<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom"><id>https://github.com/imjuya/juya-ai-daily</id><title>橘鸦AI早报</title><updated>2026-02-22T01:00:45.434017+00:00</updated><author><name>imjuya</name><email>imjuyaya@gmail.com</email></author><link href="https://github.com/imjuya/juya-ai-daily"/><link href="https://raw.githubusercontent.com/imjuya/juya-ai-daily/master/feed.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>记录人类完蛋全过程</subtitle><entry><id>https://github.com/imjuya/juya-ai-daily/issues/5</id><title>2026-02-22</title><updated>2026-02-22T01:00:46.117184+00:00</updated><content type="html"><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260222/2026022208065849501269e9_cover_921f.png" alt="" /></p>
<h1>AI 早报 2026-02-22</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=MslV6QgT3Mw">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1gLZfB8Ewq">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>开发生态</h3>
<ul>
<li>智谱为 GLM Coding Plan 规则变动与体验下降致歉并提出补偿方案 <a href="https://mp.weixin.qq.com/s/qgVsa17L5Seqw9yXr1iExQ">↗</a> <code>#1</code></li>
<li>千问推出 Qwen Coding Plan <a href="https://bailian.console.aliyun.com/">↗</a> <code>#2</code></li>
<li>Claude Code 引入内置 Git Worktree 支持 <a href="https://t.co/cjOXhUDL0i">↗</a> <code>#3</code></li>
<li>OpenAI 扩展 Batch API 支持 GPT 图像模型 <a href="https://x.com/OpenAIDevs/status/2025273441826517370">↗</a> <code>#4</code></li>
</ul>
<h3>产品应用</h3>
<ul>
<li>微软确认 Copilot 默认共享 Bing 与 Edge 数据 <a href="https://www.windowslatest.com/2026/02/19/copilot-quietly-pulls-your-data-from-other-microsoft-products-including-edge-and-msn-but-you-can-opt-out/">↗</a> <code>#5</code></li>
<li>OpenClaw 发布 v2026.2.21 版本更新 <a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.21">↗</a> <code>#6</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>Taalas 亮相固化模型推理芯片 HC1 <a href="https://chatjimmy.ai/">↗</a> <code>#7</code></li>
<li>Andrej Karpathy 评析 Claw 技术及安全隐患 <a href="https://x.com/karpathy/status/2024987174077432126">↗</a> <code>#8</code></li>
</ul>
<h3>前瞻与传闻</h3>
<ul>
<li>OpenAI 曾考虑就加拿大疑似枪手的聊天内容向警方报案 <a href="https://www.wsj.com/us-news/law/openai-employees-raised-alarms-about-canada-shooting-suspect-months-ago-b585df62">↗</a> <code>#9</code></li>
<li>据报 OpenAI 文件上调了五年收入预期 <a href="https://x.com/theinformation/status/2025280618917945476">↗</a> <code>#10</code></li>
<li>Anthropic 拟推 Claude API CLI 工具 <a href="https://github.com/anthropics/anthropic-cli">↗</a> <code>#11</code></li>
</ul>
<hr />
<h2><a href="https://mp.weixin.qq.com/s/qgVsa17L5Seqw9yXr1iExQ">智谱为 GLM Coding Plan 规则变动与体验下降致歉并提出补偿方案</a> <code>#1</code></h2>
<blockquote>
<p><strong>智谱</strong>团队就 <code>GLM Coding Plan</code> 规则变动与体验下降致歉，支持受影响用户申请退款，留存用户获赠<strong>15</strong>天时长。还允许在<strong>2月12日至16日</strong>期间误升级的用户，权益升级至无周限额的老套餐，并承诺未来核心权益调整将提前说明。</p>
</blockquote>
<p><strong>智谱团队</strong>就 <code>GLM Coding Plan</code> 规则变动与体验下降向用户致歉，承认在 <code>规则透明度</code>、<code>灰度节奏</code> 及 <code>老用户升级机制</code> 上存在失误。</p>
<p>官方说明 <code>GLM-5</code> 参数规模达 <code>GLM-4.7</code> <strong>两倍</strong>以上，采取高峰期<strong>3倍</strong>、非高峰期<strong>2倍</strong>的消耗策略，看板刷新频率已优化至<strong>10分钟</strong>。因流量激增及遭受攻击，服务按 <code>Max</code>、<code>Pro</code>、<code>Lite</code> 顺序开放，目前 <code>Max</code> 已全面开放，<code>Pro</code> 高峰期限流，<code>Lite</code> 将在之后 <code>灰度开放</code>。</p>
<p>解决方案包括：支持 <code>Lite</code>/<code>Pro</code> 用户退款；赠送已使用及留存用户<strong>15天</strong>时长；<strong>2月12日至16日</strong>误升级用户可一键升级至 <code>无周限额老套餐</code>。官方承诺未来 <code>核心权益调整</code> 将提前说明。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/f1a4210b-01bc-41a0-a19d-f66876ee58f9/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/qgVsa17L5Seqw9yXr1iExQ">https://mp.weixin.qq.com/s/qgVsa17L5Seqw9yXr1iExQ</a></li>
</ul>
<hr />
<h2><a href="https://bailian.console.aliyun.com/">千问推出 Qwen Coding Plan</a> <code>#2</code></h2>
<blockquote>
<p><strong>千问团队</strong>推出 <code>Qwen Coding Plan</code>，支持 <code>Qwen3.5-Plus</code>、<code>Qwen3-Max</code> 等最新模型，新客首月仅需 <strong>7.9 元</strong>。</p>
</blockquote>
<p><strong>千问团队</strong>近期推出 <code>Qwen Coding Plan</code>，旨在让开发者低成本体验最新模型，支持 <code>Qwen3.5-Plus</code>、<code>Qwen3-Max</code>，并适配 <code>Cursor</code>、<code>Cline</code> 等主流工具。定价方面，新客首月 <strong>7.9 元</strong>，老客享 <strong>5 折</strong>优惠。用户现可访问<strong>阿里云百炼</strong>官网开通体验。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/4913669f-1d7e-4e0d-8686-23e6764cb52b/m001.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/4913669f-1d7e-4e0d-8686-23e6764cb52b/m002.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://bailian.console.aliyun.com/">https://bailian.console.aliyun.com/</a></li>
</ul>
<hr />
<h2><a href="https://t.co/cjOXhUDL0i">Claude Code 引入内置 Git Worktree 支持</a> <code>#3</code></h2>
<blockquote>
<p><strong>Claude Code CLI</strong> 上线了内置 <code>Git Worktree</code> 支持，将此前仅限 <strong>Desktop</strong> 端的隔离能力扩展至 <code>CLI</code>，解决多个 <code>Agent</code> 并行运行时的文件冲突问题。</p>
</blockquote>
<p><strong>Claude Code</strong> 官方在 <strong>2.1.50</strong> 版本中引入了内置 <code>Git Worktree</code> 支持，将此前仅限 <code>Desktop</code> 应用的功能扩展至 <code>CLI</code>。此功能通过 <code>Git Worktree</code> 机制，允许多个 <code>Agent</code> 在同一仓库的独立工作目录中并行运行，解决了因共享工作目录导致的文件冲突与覆盖问题。</p>
<p>目前，<code>CLI</code> 端支持 <code>claude --worktree</code> 参数启动，可自动或手动命名工作树；<code>Desktop</code> 应用增设了 <code>Worktree</code> 模式开关；<code>Subagent</code> 同样支持 <code>Worktree</code> 隔离，便于执行大规模代码迁移等并行任务；用户可通过 <code>Frontmatter</code> 配置 <code>&quot;isolation&quot;: &quot;worktree&quot;</code>，使自定义 <code>Agent</code> 默认在隔离环境中运行；该设计还兼容 <code>Mercurial</code>、<code>Perforce</code> 等非 <code>Git</code> 版本控制系统，用户可通过定义 <code>Hooks</code> 实现同等隔离效果。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/3cdd1d5a-58ed-4168-82b2-b2aefcbc9499/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://t.co/cjOXhUDL0i">https://t.co/cjOXhUDL0i</a></li>
</ul>
<hr />
<h2><a href="https://x.com/OpenAIDevs/status/2025273441826517370">OpenAI 扩展 Batch API 支持 GPT 图像模型</a> <code>#4</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 宣布 <code>Batch API</code> 现已支持 <code>GPT 图像模型</code>，该功能覆盖 <code>gpt-image-1.5</code> 等多个模型，拥有独立速率限制并节省 <strong>50%</strong> 调用成本。</p>
</blockquote>
<p><strong>OpenAI</strong> 宣布其 <code>Batch API</code> 现已扩展支持 GPT 图像模型，旨在满足开发者对大规模图像生成与编辑的需求。此次更新覆盖 <code>gpt-image-1.5</code>、<code>chatgpt-image-latest</code>、<code>gpt-image-1</code> 及 <code>gpt-image-1-mini</code> <strong>四款</strong>模型。</p>
<p>开发者现可通过 <code>该 API</code> 提交异步作业，单次任务上限达 <strong>50,000</strong> 个。此外，该服务设有独立速率限制，不占用标准 <code>API</code> 配额，且相比常规调用可节省 <strong>50%</strong> 的成本。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/ee18fa85-4cee-4b83-8e7a-ed0ac14e022e/m001.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/ee18fa85-4cee-4b83-8e7a-ed0ac14e022e/m002.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/OpenAIDevs/status/2025273441826517370">https://x.com/OpenAIDevs/status/2025273441826517370</a></li>
</ul>
<hr />
<h2><a href="https://www.windowslatest.com/2026/02/19/copilot-quietly-pulls-your-data-from-other-microsoft-products-including-edge-and-msn-but-you-can-opt-out/">微软确认 Copilot 默认共享 Bing 与 Edge 数据</a> <code>#5</code></h2>
<blockquote>
<p><strong>微软</strong>确认<strong>Copilot</strong>现已默认开启数据共享机制，自动提取<strong>Bing</strong>、<strong>MSN</strong>及<strong>Edge</strong>的用户数据以增强个性化记忆。</p>
</blockquote>
<p>据 <strong>Windows Latest</strong> 报道，<strong>微软</strong>确认 <code>Copilot</code> 现默认开启数据共享机制，自动从 <strong>Bing</strong>、<strong>MSN</strong> 及 <strong>Edge</strong> 等产品提取数据以增强记忆与个性化功能。用户虽可在设置中关闭 <code>Microsoft usage data</code> 开关，但需额外点击 <code>Delete all memory</code> 方能彻底清除数据。<strong>微软</strong>强调该数据仅用于个性化定制，不用于训练 <code>AI 模型</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/324005c9-c689-42c4-8bac-ac948bcc7945/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.windowslatest.com/2026/02/19/copilot-quietly-pulls-your-data-from-other-microsoft-products-including-edge-and-msn-but-you-can-opt-out/">https://www.windowslatest.com/2026/02/19/copilot-quietly-pulls-your-data-from-other-microsoft-products-including-edge-and-msn-but-you-can-opt-out/</a></li>
</ul>
<hr />
<h2><a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.21">OpenClaw 发布 v2026.2.21 版本更新</a> <code>#6</code></h2>
<blockquote>
<p><strong>OpenClaw</strong> 发布 <strong>v2026.2.21</strong> 版本，重点支持 <code>Gemini 3.1</code>，并实施了大规模安全加固。</p>
</blockquote>
<p><strong>OpenClaw</strong> 官方近日发布 <strong>v2026.2.21</strong> 版本更新。该版本重点引入了对 <code>Gemini 3.1</code> 的支持，并实施了大规模安全加固。在功能方面，新增 <strong>Discord</strong> 流媒体传输与语音频道支持，并引入 <code>Thread-bound subagent sessions</code> 优化会话管理。针对移动端，新版本优化了 <strong>iOS</strong> 及 <strong>Watch</strong> 平台体验，提升了网关稳定性并微调了 <code>Prompt caching</code>。官方表示本次更新包含 <strong>100</strong> 多项修复，详情已发布在 <strong>GitHub</strong> 上。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/45a3e7b9-1ebe-4b01-8321-fa39decbe1dd/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/openclaw/openclaw/releases/tag/v2026.2.21">https://github.com/openclaw/openclaw/releases/tag/v2026.2.21</a></li>
</ul>
<hr />
<h2><a href="https://chatjimmy.ai/">Taalas 亮相固化模型推理芯片 HC1</a> <code>#7</code></h2>
<blockquote>
<p>AI芯片初创公司<strong>Taalas</strong>近期展示了首款芯片<code>HC1</code>。该产品通过将<code>模型权重</code>“固化”到<code>硅片</code>中，在<code>量化版</code>Llama 3.1-8B上实现了每秒超过<strong>1.5万</strong>个<code>Token</code>的<code>推理速度</code>，用户可在<code>chatjimmy.ai</code>上进行测试。<strong>Taalas</strong>目前已获得超过<strong>2亿美元</strong>融资，并计划在<strong>今年夏季</strong>推出第二款<code>推理芯片</code>。</p>
</blockquote>
<p>AI芯片初创公司<strong>Taalas</strong>发布首款产品<code>HC1</code>，采用<code>硬连线</code>技术将模型直接固化在硅片中。<code>HC1</code>基于<strong>台积电</strong><code>6nm</code>工艺，功耗约<strong>250W</strong>。据<strong>EE Times</strong>实测，其运行<code>Llama 3.1-8B</code>的速度超每秒<strong>15,000</strong>个<code>Token</code>，公司内部测试近<strong>17,000</strong>，远超<strong>Nvidia</strong>等现有硬件。该方案虽牺牲灵活性，但仅需修改<strong>两层</strong><code>掩模版</code>即可在<strong>两个月</strong>内完成定制。内部模拟数据显示，其<strong>30</strong>芯集群运行<code>DeepSeek R1</code>吞吐量达每秒<strong>12,000</strong>个<code>Token</code>，总拥有成本显著低于<code>GPU</code>。公司已融资超<strong>2亿美元</strong>，计划<strong>今夏</strong>推出第二款芯片，<strong>年底前</strong>支持前沿模型。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/b1caced2-6da8-4412-90d7-b6b6eb97a31d/m001.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/b1caced2-6da8-4412-90d7-b6b6eb97a31d/m002.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://chatjimmy.ai/">https://chatjimmy.ai/</a></li>
<li><a href="https://www.eetimes.com/taalas-specializes-to-extremes-for-extraordinary-token-speed/">https://www.eetimes.com/taalas-specializes-to-extremes-for-extraordinary-token-speed/</a></li>
</ul>
<hr />
<h2><a href="https://x.com/karpathy/status/2024987174077432126">Andrej Karpathy 评析 Claw 技术及安全隐患</a> <code>#8</code></h2>
<blockquote>
<p><strong>Andrej Karpathy</strong> 近期专门购置 <strong>Mac Mini</strong> 测试 <code>Claws</code> 技术，他将 <code>Claws</code> 定义为位于 <code>LLM Agent</code> 之上的新层级，负责任务的编排与调度。</p>
</blockquote>
<p><strong>Andrej Karpathy</strong> 近期购买 <code>Mac Mini</code> 以测试 <code>Claws</code> 技术。<strong>Karpathy</strong> 将 <code>Claws</code> 定义为位于 <code>LLM Agent</code> 之上的新层级，负责编排、调度与持久化。</p>
<p>尽管看好该概念，<strong>Karpathy</strong> 对主流实现 <code>OpenClaw</code> 持保留态度。他称 <code>OpenClaw</code> 是一个由 <code>vibe coding</code> 构成的 <strong>40万行代码</strong> 庞然大物，存在 <code>RCE（远程代码执行）</code> 漏洞和供应链投毒等严重安全隐患，现状堪比“安全噩梦”。</p>
<p>他更看好 <code>NanoClaw</code> 等轻量级方案。<code>NanoClaw</code> 核心引擎仅约 <strong>4000行代码</strong>，且默认在 <code>容器</code> 中运行。其架构特点是通过 <code>Skills 指令</code> 修改源码来集成功能，而非依赖 <code>配置文件</code>，<strong>Karpathy</strong> 赞赏其为一种防止配置混乱的新范式。与此同时，社区也涌现出 <code>nanobot</code>、<code>nullclaw</code> 等多个同类项目。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/75f00d96-2986-4a0b-9a49-bf4ba0e173b0/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/karpathy/status/2024987174077432126">https://x.com/karpathy/status/2024987174077432126</a></li>
</ul>
<hr />
<h2><a href="https://www.wsj.com/us-news/law/openai-employees-raised-alarms-about-canada-shooting-suspect-months-ago-b585df62">OpenAI 曾考虑就加拿大疑似枪手的聊天内容向警方报案</a> <code>#9</code></h2>
<blockquote>
<p>据**《华尔街日报》<strong>报道，加拿大一名涉嫌杀害</strong>8人**的凶手曾利用<code>ChatGPT</code>探讨枪支暴力，<strong>OpenAI</strong>虽封禁了其账号，但认为未达到举报标准，未在案发前通知警方。</p>
</blockquote>
<p>据**《华尔街日报》<strong>报道，涉嫌在加拿大Tumbler Ridge杀害</strong>8人<strong>的</strong>18岁<strong>嫌疑人</strong>Jesse Van Rootselaar**，曾在<strong>OpenAI</strong>的<code>ChatGPT</code>上进行涉及枪支暴力的对话。相关记录于<strong>2025年6月</strong>被<strong>OpenAI</strong>的监控工具标记，其账号亦遭封禁。报道指出，<strong>OpenAI</strong>员工曾就是否向加拿大执法部门举报进行内部辩论，但最终在事发前未采取行动。<strong>OpenAI</strong>发言人回应称，该嫌疑人的活动未达到向执法部门报告的标准，公司是在事件发生后才联系了加拿大当局。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.wsj.com/us-news/law/openai-employees-raised-alarms-about-canada-shooting-suspect-months-ago-b585df62">https://www.wsj.com/us-news/law/openai-employees-raised-alarms-about-canada-shooting-suspect-months-ago-b585df62</a></li>
</ul>
<hr />
<h2><a href="https://x.com/theinformation/status/2025280618917945476">据报 OpenAI 文件上调了五年收入预期</a> <code>#10</code></h2>
<blockquote>
<p>据 <strong>The Information</strong> 报道，<strong>OpenAI</strong> 大幅上调五年期收入预测，预计今年营收达 <strong>300 亿美元</strong>，目标是 <strong>2030 年</strong>实现 <strong>1500 亿美元</strong>的消费者销售。<code>ChatGPT</code> 周活用户已升至 <strong>9.1 亿</strong>，但高昂的 <code>算力成本</code> 导致毛利率下滑，公司预计到 <strong>2030 年</strong>在基础设施上的投入将高达 <strong>6650 亿美元</strong>，并计划在当年实现 <code>现金流转正</code>。</p>
</blockquote>
<p>据媒体 <strong>The Information</strong> 报道，<strong>OpenAI</strong> 在内部文件中大幅上调<strong>五年期</strong>收入预测约 <strong>27%</strong>，但预计到 <strong>2030 年</strong>现金消耗将高达 <strong>1110 亿至 1120 亿美元</strong>。</p>
<p>文件显示，公司去年收入达 <strong>131 亿美元</strong>，今年和明年的收入目标分别为 <strong>300 亿</strong>和 <strong>620 亿美元</strong>。其中，面向消费者的销售预计今年翻倍至 <strong>170 亿美元</strong>，并计划在 <strong>2030 年</strong>达到 <strong>1500 亿美元</strong>。</p>
<p>高额的 <code>算力</code> 成本是主要支出。公司预计到 <strong>2030 年</strong>在基础设施和计算资源上的投入将达 <strong>6650 亿美元</strong>，导致 <code>调整后毛利率</code> 从 <strong>40%</strong> 降至 <strong>33%</strong>，未达预期目标。今年的总支出预计为 <strong>250 亿美元</strong>，明年将增至 <strong>570 亿美元</strong>。</p>
<p>用户增长方面，<strong>ChatGPT</strong> <code>周活跃用户</code>数已达 <strong>9.1 亿</strong>，受益于 <code>GPT-5.1</code> 和 <code>5.2</code> 等更新带来的体验提升，公司长期目标是在 <strong>2030 年</strong>实现 <strong>27.5 亿</strong><code>周活跃用户</code>。尽管面临巨额投入，<strong>OpenAI</strong> 仍预计在 <strong>2030 年</strong>实现 <code>现金流转正</code>，截至去年年底其账面现金约为 <strong>400 亿美元</strong>。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/theinformation/status/2025280618917945476">https://x.com/theinformation/status/2025280618917945476</a></li>
</ul>
<hr />
<h2><a href="https://github.com/anthropics/anthropic-cli">Anthropic 拟推 Claude API CLI 工具</a> <code>#11</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 正在开发一款专门用于 <strong>Claude API</strong> 的 <code>命令行工具</code> <strong>Anthropic CLI</strong>，目前该项目的 <strong>GitHub</strong> <code>仓库</code> 已经上线。</p>
</blockquote>
<p>据<strong>Anthropic</strong>成员<strong>Katelyn Lesse</strong>透露，公司正在开发一款针对<code>Claude API</code>的命令行工具<strong>Anthropic CLI</strong>。她表示，团队正在推进该工具的发布，并建议用户“敬请期待”。目前，该项目的<strong>GitHub</strong>代码仓库刚刚创建，开发者可先行关注。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/921fde4c-e9c3-4459-a0bf-b26a9fe41e50/d7cfe691-3514-495f-89bf-a1d04203714f/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/anthropics/anthropic-cli">https://github.com/anthropics/anthropic-cli</a></li>
</ul>
<hr />
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content><link href="https://github.com/imjuya/juya-ai-daily/issues/5"/><published>2026-02-22T00:32:33+00:00</published></entry><entry><id>https://github.com/imjuya/juya-ai-daily/issues/4</id><title>2026-02-21</title><updated>2026-02-22T01:00:46.349095+00:00</updated><content type="html"><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260221/20260221084518976101edba_cover_46a9.png" alt="" /></p>
<h1>AI 早报 2026-02-21</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=GddxDudZ_bE">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1XAf7BnEy6">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>开发生态</h3>
<ul>
<li>Anthropic 员工回应 Claude Agent SDK 及 OAuth 令牌争议 <code>#1</code></li>
<li>Claude Code 桌面版发布重大更新 <code>#2</code></li>
<li>Anthropic 发布 Claude Code Security <code>#3</code></li>
<li>GPT-5.3-Codex-Spark 升级速率超 1200 tokens/s <code>#4</code></li>
<li>Google CLI 开启 3.1 Pro 访问权限 <code>#5</code></li>
<li>Ollama 发布新版原生集成 Cline 与 Pi <code>#6</code></li>
</ul>
<h3>产品应用</h3>
<ul>
<li>OpenAI 扩充 ChatGPT Thinking 模式上下文窗口 <code>#7</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>智谱 MiniMax 市值接连超越快手京东 <code>#8</code></li>
<li>GGML 团队加入 Hugging Face <code>#9</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>Karpathy 称传统 App Store 模式将过时 <code>#10</code></li>
</ul>
<h3>前瞻与传闻</h3>
<ul>
<li>OpenAI 或将推出 ChatGPT Pro Lite 订阅 <code>#11</code></li>
<li>Google DeepMind 宣布将发布 Gemma 新模型 <code>#12</code></li>
<li>传 OpenAI 打造首款摄像头 AI 智能音箱 <code>#13</code></li>
<li>OpenAI 传获软银领衔百亿注资 <code>#14</code></li>
</ul>
<hr />
<h2><a href="https://x.com/trq212/status/2024212380142752025">Anthropic 员工回应 Claude Agent SDK 及 OAuth 令牌争议</a> <code>#1</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 员工回应了关于 <code>Claude Agent SDK</code> 及 <code>OAuth</code> 令牌使用的争议，称此前的文档变更仅为措辞调整，鼓励开发者使用 <code>Agent SDK</code> 进行本地实验，但如果基于该 <code>SDK</code> 构建商业产品，则必须通过 <code>API Key</code> 进行调用。</p>
</blockquote>
<p>针对<code>Claude Agent SDK</code>及<code>OAuth令牌</code>使用政策的争议，<strong>Anthropic</strong>员工<strong>Thariq</strong>近日澄清，引发混淆的文档变更仅为措辞调整，并未改变<code>Agent SDK</code>及<code>MAX</code>订阅的使用方式。官方立场鼓励使用<code>Agent SDK</code>进行本地开发与实验，但若基于其构建商业产品，则需使用<code>API Key</code>。其表示将优化文档表述以消除误解。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/5f83d37d-0684-4302-9c27-9590d079fb04/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/trq212/status/2024212380142752025">https://x.com/trq212/status/2024212380142752025</a></li>
</ul>
<hr />
<h2><a href="https://x.com/claudeai/status/2024937960572104707">Claude Code 桌面版发布重大更新</a> <code>#2</code></h2>
<blockquote>
<p><code>Claude Code</code> 桌面版迎来重大更新，新增 <code>Server Previews</code>、<code>Local Code Review</code>、<code>PR Monitoring</code> 及 <code>Session Mobility</code> <strong>四大</strong>核心功能。<code>Claude</code> 现在能直接在桌面端启动服务器预览应用，自动审查<code>代码</code>中的<code>Bug</code>，并监控<code>CI</code>状态，实现自动修复与合并。</p>
</blockquote>
<p><strong>Claude</strong> 官方宣布 <code>Claude Code</code> 桌面版迎来重大更新，新增 <code>Server previews</code>、<code>Local code review</code>、<code>PR monitoring</code> 及 <code>Session mobility</code> 核心功能。更新后，<strong>Claude</strong> 可在桌面端直接启动开发服务器并预览应用，结合日志与截图进行迭代；代码提交前支持行内 Bug 审查；PR 流程中具备 <code>Auto-fix</code> 和 <code>Auto-merge</code> 能力，可自动修复故障并在通过检查后合并代码。此外，<code>Session mobility</code> 实现了 <code>CLI</code> 与桌面、云端及移动端间的会话无缝迁移。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/cd6a6d9a-d92c-4a06-92ea-cb636b11effd/m001.gif" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/claudeai/status/2024937960572104707">https://x.com/claudeai/status/2024937960572104707</a></li>
</ul>
<hr />
<h2><a href="https://www.anthropic.com/news/claude-code-security">Anthropic 发布 Claude Code Security</a> <code>#3</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 推出了集成在 <code>Claude Code</code> 中的新功能 <code>Claude Code Security</code>，该功能由 <code>Claude Opus 4.6</code> 驱动，能像人类安全专家一样对代码进行推理，从而发现传统工具难以捕捉的业务逻辑漏洞。<strong>Enterprise</strong> 和 <strong>Team</strong> 客户以及开源项目维护者现可申请试用。</p>
</blockquote>
<p><strong>Anthropic</strong> 官方宣布推出 <code>Claude Code Security</code>，现处于有限研究预览阶段。该功能集成在 <code>Claude Code (Web)</code> 中，由 <code>Claude Opus 4.6</code> 驱动。不同于依赖<code>模式匹配</code>的传统<code>静态分析工具</code>，该工具能像人类一样推理代码，通过理解组件交互和数据流向，发现<code>业务逻辑缺陷</code>等<code>复杂漏洞</code>。官方数据显示，该模型已协助团队在开源代码中发现超过 <strong>500</strong> 个隐藏漏洞。所有发现均经过多阶段验证和评级，修复需经人工批准。目前，<strong>Enterprise</strong> 和 <strong>Team</strong> 客户及开源项目维护者均可申请访问。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/6c68bcc6-1913-48d7-80c1-06f7ac6ad98f/m001.gif" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/news/claude-code-security">https://www.anthropic.com/news/claude-code-security</a></li>
</ul>
<hr />
<h2><a href="https://x.com/thsottiaux/status/2024947946849186064">GPT-5.3-Codex-Spark 升级速率超 1200 tokens/s</a> <code>#4</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 宣布 <code>GPT-5.3-Codex-Spark</code> 模型速度得到提升，突破每秒 <strong>1200</strong> 个 <code>tokens</code>，后续将推出更多全局性速度优化。</p>
</blockquote>
<p><code>GPT-5.3-Codex-Spark</code> 官方宣布该模型已完成性能升级，速度提升约 <strong>30%</strong>，当前服务速度已超 <strong>1200</strong> tokens/s。此外，官方预告未来将在全范围内推出更多速度优化计划。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/5391a66f-9c5d-4547-8fb6-a7b502695166/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/thsottiaux/status/2024947946849186064">https://x.com/thsottiaux/status/2024947946849186064</a></li>
</ul>
<hr />
<h2><a href="https://x.com/geminicli/status/2024967271681233356">Google CLI 开启 3.1 Pro 访问权限</a> <code>#5</code></h2>
<blockquote>
<p><code>Gemini CLI</code> 目前已向 <strong>AI Ultra</strong> 和 <strong>Workspace Ultra</strong> 账户开放 <code>Gemini 3.1 Pro</code> 访问权限。官方将根据系统容量逐步扩大访问范围。</p>
</blockquote>
<p><strong>Gemini CLI</strong> 团队正在逐步推送 <code>Gemini 3.1 Pro</code> 访问权限。目前获权用户包括：通过 <strong>Google</strong> 登录的 <strong>AI Ultra</strong> 和 <strong>Workspace Ultra</strong> 账户、拥有该模型权限的 <strong>AI Studio</strong> 及 <strong>Vertex AI</strong> 项目 <code>API Key</code> 持有者，以及小部分其他登录用户。用户可在 <code>CLI</code> 中输入 <code>/model</code> 命令验证状态。官方表示将根据系统容量逐步扩大范围。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/495b9cf1-b67e-4a5c-b1a9-c04f1a9f63b0/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/geminicli/status/2024967271681233356">https://x.com/geminicli/status/2024967271681233356</a></li>
<li><a href="https://github.com/google-gemini/gemini-cli/discussions/19724">https://github.com/google-gemini/gemini-cli/discussions/19724</a></li>
</ul>
<hr />
<h2><a href="https://x.com/ollama/status/2024987888870416673">Ollama 发布新版原生集成 Cline 与 Pi</a> <code>#6</code></h2>
<blockquote>
<p><strong>Ollama</strong> 发布新版，集成了 <code>Cline</code> 和 <code>Pi</code>，用户通过指令 <code>ollama launch cline</code> 或 <code>ollama launch pi</code> 即可开箱即用。</p>
</blockquote>
<p><strong>Ollama</strong> 发布 <strong>0.16.3</strong> 版本，新增对 <strong>Cline</strong> 和 <strong>Pi</strong> 的开箱即用集成支持，用户可通过 <code>ollama launch</code> 指令直接启动相应服务。<strong>Cline</strong> 作者 <strong>Saoud Rizwan</strong> 对此表示，尽管目前尚处早期，但未来笔记本电脑运行的开源模型将足以完成大部分工作，很高兴与 <strong>Ollama</strong> 合作推动这一愿景成为现实。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/f33b7761-2fb5-429e-83e9-28f1e22a3e96/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/ollama/status/2024987888870416673">https://x.com/ollama/status/2024987888870416673</a></li>
</ul>
<hr />
<h2><a href="https://x.com/trq212/status/2024212380142752025">OpenAI 扩充 ChatGPT Thinking 模式上下文窗口</a> <code>#7</code></h2>
<blockquote>
<p><strong>ChatGPT</strong> 更新日志显示，<strong>ChatGPT</strong> 的 <code>Thinking 模式</code> <code>上下文窗口</code> 已扩容至 <strong>256k</strong> <code>tokens</code>。</p>
</blockquote>
<p>根据 <strong>ChatGPT</strong> 更新日志，<strong>ChatGPT</strong> 的 <code>Thinking 模式</code>上下文窗口容量已扩充。当用户手动启用该模式时，其总上下文窗口从此前的 <strong>196k tokens</strong> 提升至 <strong>256k tokens</strong>。新版本的具体配置为 <strong>128k tokens</strong> 的输入限制和 <strong>128k tokens</strong> 的最大输出限制。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/366a06ca-7075-43cb-991b-9cc0217ac475/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/trq212/status/2024212380142752025">https://x.com/trq212/status/2024212380142752025</a></li>
</ul>
<hr />
<h2><a href="https://mp.weixin.qq.com/s/neThU7OwEOM7S_TSSroI4A">智谱 MiniMax 市值接连超越快手京东</a> <code>#8</code></h2>
<blockquote>
<p>据报道，<strong>智谱</strong>与 <strong>MiniMax</strong> 港股股价大涨并创新高，市值已连超<strong>携程</strong>、<strong>快手</strong>及<strong>京东</strong>。</p>
</blockquote>
<p>据报道，大模型公司<strong>智谱</strong>与 <strong>MiniMax</strong> 近期港股股价大幅上涨，创上市以来新高。两家公司市值已接连超越<strong>携程</strong>、<strong>快手</strong>及<strong>京东</strong>，并逼近<strong>泡泡玛特</strong>与<strong>百度</strong>。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/neThU7OwEOM7S_TSSroI4A">https://mp.weixin.qq.com/s/neThU7OwEOM7S_TSSroI4A</a></li>
</ul>
<hr />
<h2><a href="https://huggingface.co/blog/ggml-joins-hf">GGML 团队加入 Hugging Face</a> <code>#9</code></h2>
<blockquote>
<p><strong>Hugging Face</strong> 宣布 <strong>GGML</strong> 组织及其创始人 <strong>Georgi Gerganov</strong> 团队正式加入 <strong>Hugging Face</strong>，双方将结合 <code>llama.cpp</code> 在本地推理的优势与 <code>Transformers</code> 的模型定义能力，共同推动 <code>Local AI</code> 发展。</p>
</blockquote>
<p><strong>Hugging Face</strong> 官方宣布，<strong>GGML</strong> 组织及创始人 <strong>Georgi Gerganov</strong> 团队正式加入。双方将结合 <code>llama.cpp</code> 本地推理优势与 <code>transformers</code> 模型定义能力，推动 Local AI 发展。官方确认，原团队保留对 <code>llama.cpp</code> 的 <strong>100%</strong> 技术决策权与社区领导权，项目维持开源模式。未来将致力于实现“一键式”模型部署与优化 <strong>GGML</strong> 用户体验，使本地推理成为云端的有力替代。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/df4ae420-98e2-4f12-a3ff-b44d303a1917/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://huggingface.co/blog/ggml-joins-hf">https://huggingface.co/blog/ggml-joins-hf</a></li>
</ul>
<hr />
<h2><a href="https://x.com/karpathy/status/2024583544157458452">Karpathy 称传统 App Store 模式将过时</a> <code>#10</code></h2>
<blockquote>
<p><strong>Andrej Karpathy</strong> 展示了他利用 <code>Claude</code> 仅用 <strong>1 小时</strong>就构建出的定制化心肺训练仪表盘，以此预言传统的 <strong>App Store</strong> 模式将过时，未来将由 <code>LLM Agent</code> 即时生成满足特定长尾需求的软件。</p>
</blockquote>
<p><strong>Andrej Karpathy</strong>通过构建定制化心肺训练追踪仪表盘，展示了他对未来“高度定制化软件”的设想。为执行一项为期<strong>8周</strong>的计划，旨在通过<code>Zone 2</code>训练与<code>HIIT</code>将静息心率从<strong>50</strong>降至<strong>45</strong>，他利用<code>Claude</code>在<strong>1小时</strong>内编写了一个约<strong>300行代码</strong>的<code>Web应用</code>。该应用通过<code>逆向工程</code><strong>Woodway</strong>跑步机云端<code>API</code>获取原始数据，尽管过程中出现单位换算和日历匹配错误需人工修复，但他认为这相比于<strong>2年前</strong>完成同样工作所需的<strong>10小时</strong>，效率已大幅提升。</p>
<p><strong>Karpathy</strong>指出，传统<strong>App Store</strong>模式正变得过时，因为针对高度特定的长尾需求，<code>LLM Agent</code>能够即时生成完全贴合需求的定制应用。他认为当前行业进展缓慢，<strong>99%<strong>的产品本质上作为传感器，却仍只提供人类可读的文档和<code>前端</code>，缺乏<code>AI原生</code>的<code>CLI</code>和<code>API</code>，迫使Agent进行<code>逆向工程</code>。他展望未来，行业应重构为具备<code>Agent原生工效学</code>的传感器与<code>执行器</code>服务，通过“<code>LLM胶水</code>”进行编排，并借助拥有大量个人上下文的<code>AI</code>，最终实现仅需</strong>1分钟</strong>即可构建高度定制、临时化应用程序的目标。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/98e67eea-963d-4845-aff0-23424da380c2/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/karpathy/status/2024583544157458452">https://x.com/karpathy/status/2024583544157458452</a></li>
</ul>
<hr />
<h2><a href="https://x.com/btibor91/status/2024992285591818329">OpenAI 或将推出 ChatGPT Pro Lite 订阅</a> <code>#11</code></h2>
<blockquote>
<p>开发者<strong>Tibor Blaho</strong>在<code>ChatGPT</code>网页代码中发现了名为<code>ChatGPT Pro Lite</code>的新订阅层级，外界推测定价可能在<strong>50</strong>或<strong>100美元</strong>，但目前<strong>OpenAI</strong>官方尚未确认该消息。</p>
</blockquote>
<p>据开发者 <strong>Tibor Blaho</strong> 发现， <strong>ChatGPT</strong> 网页应用代码中出现了对“ <code>ChatGPT Pro Lite</code> ”计划的引用。此举引发了社区关于 <strong>OpenAI</strong> 或将推出新订阅层级的猜测，据推测其定价可能在 <strong>50至100美元</strong>。目前，官方尚未对该计划的存在、功能详情或上线时间做出任何确认。所有信息均源自代码线索，相关讨论仅为推测。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/46a9251e-3ea4-4df4-a688-cf90f543a579/43049b7c-9410-4e2c-a9ef-852f5c62f26b/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/btibor91/status/2024992285591818329">https://x.com/btibor91/status/2024992285591818329</a></li>
</ul>
<hr />
<h2>Google DeepMind 宣布将发布 Gemma 新模型 <code>#12</code></h2>
<blockquote>
<p><strong>Google DeepMind</strong>联合创始人<strong>Demis Hassabis</strong>透露，即将发布针对<code>边缘设备</code>进行优化的<code>开源模型``Gemma</code>新版本。</p>
</blockquote>
<p>据社交媒体信息，<strong>Google DeepMind</strong>联合创始人<strong>Demis Hassabis</strong>近期在印度透露，公司将“很快”发布开源模型<code>Gemma</code>的新版本。<strong>Hassabis</strong>强调，新版本将针对<code>边缘设备</code>进行优化，具备强大性能，旨在为<code>资源受限环境</code>提供支持，拓展<code>终端</code>及<code>边缘计算</code>场景的能力边界。</p>
<hr />
<h2><a href="https://www.theinformation.com/articles/inside-openai-team-developing-ai-devices">传 OpenAI 打造首款摄像头 AI 智能音箱</a> <code>#13</code></h2>
<blockquote>
<p>据报道，<strong>OpenAI</strong>正研发一款配备摄像头的智能音箱作为首款<code>AI硬件</code>。该设备能通过<code>视觉感知</code>环境与用户面部，提供主动建议及<code>人脸识别</code>购物功能，预计售价<strong>200至300美元</strong>，最早<strong>2027年初</strong>上市。</p>
</blockquote>
<p>据报道，<strong>OpenAI</strong>正与前苹果设计师<strong>Jony Ive</strong>合作，组建一支超<strong>200</strong>人的团队研发<code>AI</code>硬件设备。其首款产品或为一款带摄像头的智能音箱，该设备可通过摄像头感知用户及环境，内置类<code>Face ID</code>的面部识别以支持交互，并能主动提供建议。产品售价预计<strong>200</strong>至<strong>300</strong>美元，最早或于<strong>2027年初</strong>上市。<strong>OpenAI</strong>还在探索智能灯、<code>AI</code>眼镜及耳机等产品，但这些项目尚处早期，存在被取消可能，预计<strong>2028年</strong>或更晚面世。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.theinformation.com/articles/inside-openai-team-developing-ai-devices">https://www.theinformation.com/articles/inside-openai-team-developing-ai-devices</a></li>
<li><a href="https://the-decoder.com/openai-is-building-a-200-to-300-smart-speaker-that-tells-you-when-to-go-to-bed/">https://the-decoder.com/openai-is-building-a-200-to-300-smart-speaker-that-tells-you-when-to-go-to-bed/</a></li>
</ul>
<hr />
<h2><a href="https://the-decoder.com/nvidia-reportedly-set-to-invest-30-billion-in-openai/">OpenAI 传获软银领衔百亿注资</a> <code>#14</code></h2>
<blockquote>
<p>据多家媒体报道，<strong>OpenAI</strong> 正在推进新一轮巨额融资，<strong>软银</strong>预计注资 <strong>300 亿美元</strong>。此外，<strong>路透社</strong>消息称，<strong>英伟达</strong>也计划投资 <strong>300 亿美元</strong>，<strong>亚马逊</strong>可能参与其中。</p>
</blockquote>
<p>据多家媒体报道，<strong>OpenAI</strong>正在推进新一轮融资。<strong>The Information</strong>援引消息称，<strong>软银</strong>预计将作为锚定投资者注资<strong>300亿美元</strong>，<strong>亚马逊</strong>和<strong>英伟达</strong>也可能参与投资，金额或达<strong>数百亿美元</strong>。</p>
<p>针对<strong>英伟达</strong>的投资动向，<strong>路透社</strong>援引知情人士透露，<strong>英伟达</strong>也计划向<strong>OpenAI</strong>投资<strong>300亿美元</strong>。目前，上述投资计划均属市场传闻，官方尚未发布正式公告。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://the-decoder.com/nvidia-reportedly-set-to-invest-30-billion-in-openai/">https://the-decoder.com/nvidia-reportedly-set-to-invest-30-billion-in-openai/</a></li>
<li><a href="https://x.com/theinformation/status/2024865405458661503">https://x.com/theinformation/status/2024865405458661503</a></li>
</ul>
<hr />
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content><link href="https://github.com/imjuya/juya-ai-daily/issues/4"/><published>2026-02-21T01:34:11+00:00</published></entry><entry><id>https://github.com/imjuya/juya-ai-daily/issues/3</id><title>2026-02-20</title><updated>2026-02-22T01:00:46.593480+00:00</updated><content type="html"><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260220/202602200848013165970043_cover_1636.png" alt="" /></p>
<h1>AI 早报 2026-02-20</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=XLvV1_DEeBM">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1YXZBBCE86">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>精选</h3>
<ul>
<li>Google发布Gemini 3.1 Pro Preview <code>#1</code></li>
<li>Anthropic 明确禁止 Claude 订阅接入第三方 <code>#2</code></li>
<li>Anthropic发布Claude API自动缓存 <code>#3</code></li>
</ul>
<h3>模型发布</h3>
<ul>
<li>Zyphra发布首个大脑数据基础模型ZUNA <code>#4</code></li>
<li>Jina AI发布jina-embeddings-v5-text <code>#5</code></li>
</ul>
<h3>开发生态</h3>
<ul>
<li>Google Jules新增CI修复与提交署名 <code>#6</code></li>
<li>Hugging Face推出Coding Agent 免费微调模型功能 <code>#7</code></li>
<li>OpenRouter上线模型 Benchmarks 页面 <code>#8</code></li>
<li>Cline CLI npm包遭遇供应链攻击 <code>#9</code></li>
</ul>
<h3>产品应用</h3>
<ul>
<li>OpenAI优化ChatGPT交互式代码块 <code>#10</code></li>
<li>Anthropic 向 Pro 用户开放 Claude in PowerPoint <code>#11</code></li>
<li>网易有道开源个人助理Agent LobsterAI <code>#12</code></li>
<li>Google Labs发布Pomelli影棚级产品照功能 <code>#13</code></li>
<li>NotebookLM发布幻灯片修订及PPTX导出 <code>#14</code></li>
<li>YouTube扩展对话式AI至电视平台 <code>#15</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>OpenAI向AI对齐研究基金捐赠 750 万美元 <code>#16</code></li>
<li>OpenAI联手塔塔集团布局印度市场 <code>#17</code></li>
<li>传Ineffable寻求十亿美元种子轮融资 <code>#18</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>Anthropic发布关于AI Agent自主性的实证研究报告 <code>#19</code></li>
<li>强化学习奠基人Sutton提出经验时代论 <code>#20</code></li>
</ul>
<h3>前瞻与传闻</h3>
<ul>
<li>传OpenAI正开发ChatGPT成人模式 <code>#21</code></li>
</ul>
<hr />
<h2><a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro">Google发布Gemini 3.1 Pro Preview</a> <code>#1</code></h2>
<blockquote>
<p><strong>Google</strong> 发布了 <code>Gemini 3.1 Pro Preview</code>，该模型强化了<code>推理能力</code>，显著增强了<code>代码生成能力</code>和 <code>Agent 工具调用</code>的稳定性。新版本<code>API</code>新增<code>medium</code>思考模式。目前该模型已通过 <code>Gemini App</code>、<code>AI Studio</code>及 <strong>Antigravity</strong> 等渠道开放。定价与前代保持一致。</p>
</blockquote>
<p><strong>Google</strong>发布<code>Gemini 3.1 Pro Preview</code>，这是其<code>3 Pro系列</code>的首个更新，距前代发布约<strong>三个月</strong>。该Preview版本面向开发者、企业与消费者，重点提升了<code>推理能力</code>、<code>软件工程可靠性</code>与<code>Agent任务稳定性</code>。</p>
<p>在<code>ARC-AGI-2</code>基准测试中，该模型得分达<strong>77.1%</strong>，较前代<code>Gemini 3 Pro</code>的<strong>31.1%<strong>实现翻倍以上增长。在其它专业评测中，该模型在<code>GPQA Diamond</code>科学知识测试中得分超</strong>94%</strong>，<code>SWE-Bench Verified</code>代码修复任务得分达<strong>80.6%</strong>，<code>APEX-Agents</code>长链任务得分从<strong>18.4%<strong>提升至</strong>33.5%</strong>。</p>
<p>技术参数方面，模型维持<code>100万token</code>的上下文处理能力，并将<code>API</code>文件上传限制从<strong>20MB</strong>提升至<strong>100MB</strong>。模型还引入了<code>medium</code>思考等级，并推出<code>专属端点</code>以优化<code>混合工具调用</code>的可靠性。</p>
<p>定价与<code>Gemini 3 Pro</code>保持一致，该模型已通过<code>Google AI App</code>、<code>NotebookLM</code>及<code>AI Studio</code>、<code>Vertex AI</code>等开发者工具开放，并登陆了多家第三方平台。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/05f29e08-e47b-42bb-b5ed-21294a7bb06d/m001.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/05f29e08-e47b-42bb-b5ed-21294a7bb06d/m002.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/05f29e08-e47b-42bb-b5ed-21294a7bb06d/m003.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro">https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro</a></li>
</ul>
<hr />
<h2><a href="https://code.claude.com/docs/en/legal-and-compliance">Anthropic 明确禁止 Claude 订阅接入第三方</a> <code>#2</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 更新了 <code>Claude Code</code> 的使用条款，明确禁止将 <strong>Free</strong>、<strong>Pro</strong> 和 <strong>Max</strong> 计划的 <code>OAuth Token</code> 用于任何第三方工具或 <code>Agent SDK</code>。</p>
</blockquote>
<p><strong>Anthropic</strong>近期更新了<code>Claude Code</code>的法律与合规文档，重点明确了认证机制的使用范围与限制。官方规定，通过<strong>Free、Pro和Max订阅计划</strong>获取的<code>OAuth Token</code>仅限用于<code>Claude Code</code>和<code>Claude.ai</code>，严禁将其用于包括<code>Agent SDK</code>在内的任何第三方产品、工具或服务，否则将被视为违反消费者服务条款。官方要求，构建产品或服务的开发者必须通过<code>Claude Console</code>或受支持的云提供商使用<code>API Key</code>进行认证，并保留在无事先通知的情况下采取强制执行措施的权利。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/8d38fbb8-5459-4728-9ff3-e74dbd9d720f/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://code.claude.com/docs/en/legal-and-compliance">https://code.claude.com/docs/en/legal-and-compliance</a></li>
<li><a href="https://www.anthropic.com/legal/commercial-terms">https://www.anthropic.com/legal/commercial-terms</a></li>
</ul>
<hr />
<h2><a href="https://x.com/i/article/2024515623544639493">Anthropic发布Claude API自动缓存</a> <code>#3</code></h2>
<blockquote>
<p><strong>Anthropic</strong>为<code>Claude API</code>上线了自动提示词缓存功能，开发者只需设置一个<code>cache_control</code>参数， 系统即可自动缓存系统指令和历史记录等上下文。</p>
</blockquote>
<p><strong>Anthropic</strong> 近期为 <code>Claude API</code> 引入自动 <code>Prompt Caching</code>（提示词缓存）功能，旨在通过复用计算结果降低多轮对话的延迟与成本。开发者只需在 <code>API</code> 请求中设置单个 <code>cache_control</code> 参数，系统便会自动缓存该参数之前的上下文，如系统指令、工具描述等。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/29350904-bf06-40e1-9fe9-05e67d415718/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/i/article/2024515623544639493">https://x.com/i/article/2024515623544639493</a></li>
</ul>
<hr />
<h2><a href="https://huggingface.co/Zyphra/ZUNA">Zyphra发布首个大脑数据基础模型ZUNA</a> <code>#4</code></h2>
<blockquote>
<p><strong>Zyphra</strong> 正式发布了首个基于大脑数据训练的基础模型 <code>ZUNA</code>。这是一个拥有 <strong>3.8 亿</strong> 参数的 <code>掩码扩散自编码器</code>，能够高效解决 <code>头皮脑电图信号</code> 的去噪与缺失通道重建问题。</p>
</blockquote>
<p><strong>Zyphra</strong>发布首个基于大脑数据训练的基础模型<code>ZUNA</code>，这是一个<strong>380M</strong>参数的<code>掩码扩散自编码器</code>，旨在对<code>EEG信号</code>进行去噪、缺失通道重建及上采样。该模型基于约<strong>200万</strong>通道小时的公开数据训练，据官方称，其重建精度显著优于广泛使用的<code>MNE</code>插值方法，尤其在通道丢失率超**75%**或高倍上采样场景下优势明显。</p>
<p>技术上，<code>ZUNA</code>通过将连续信号压缩为<code>Token</code>并引入<code>4-D RoPE位置嵌入</code>，实现了对异构<code>EEG数据</code>的高效处理。目前，该模型已采用<code>Apache 2.0</code>协议开源，支持消费级<code>GPU</code>运行。官方强调<code>ZUNA</code>仅供研究使用，尚未验证医疗功效，并计划在未来开源相关数据及基础设施。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/3ea470a2-2862-4880-a2f0-7458ceef45a1/m001.gif" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://huggingface.co/Zyphra/ZUNA">https://huggingface.co/Zyphra/ZUNA</a></li>
<li><a href="https://github.com/Zyphra/zuna">https://github.com/Zyphra/zuna</a></li>
<li><a href="https://www.zyphra.com/zuna-technical-paper">https://www.zyphra.com/zuna-technical-paper</a></li>
</ul>
<hr />
<h2><a href="https://jina.ai/news/jina-embeddings-v5-text-distilling-4b-quality-into-sub-1b-multilingual-embeddings/">Jina AI发布jina-embeddings-v5-text</a> <code>#5</code></h2>
<blockquote>
<p><strong>Jina AI</strong> 发布并开源了<code>文本嵌入模型</code> <code>jina-embeddings-v5-text</code>，包含 <code>Small</code> 和 <code>Nano</code> 两个版本。</p>
</blockquote>
<p><strong>Jina AI</strong> 发布<strong>第五代</strong>文本嵌入模型系列 <code>jina-embeddings-v5-text</code>，包含 <strong>6.77 亿</strong>参数的 <code>small</code> 和 <strong>2.39 亿</strong>参数的 <code>nano</code> 两个版本。官方称，该系列结合模型蒸馏与任务特定 <code>LoRA</code> 适配器技术，实现了同级最优性能。其中，<code>small</code> 模型在 <code>MMTEB</code> 基准得分 <strong>67.0</strong>，支持 <strong>32K</strong> 上下文及 <strong>119 种</strong>语言；<code>nano</code> 模型则专为边缘部署优化，支持 <strong>8K</strong> 上下文。两款模型均支持 <code>Matryoshka</code> 嵌入截断与二进制量化，权重已依据 <code>CC BY-NC 4.0</code> 协议在 <code>Hugging Face</code> 公开，并提供 <code>API</code>、<code>GGUF</code> 及 <code>MLX</code> 等多种部署方式。此外，官方透露正开发多模态版本。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/191aa50e-e89c-49cf-b1d8-25a03efc6df7/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://jina.ai/news/jina-embeddings-v5-text-distilling-4b-quality-into-sub-1b-multilingual-embeddings/">https://jina.ai/news/jina-embeddings-v5-text-distilling-4b-quality-into-sub-1b-multilingual-embeddings/</a></li>
<li><a href="https://arxiv.org/abs/2602.15547">https://arxiv.org/abs/2602.15547</a></li>
<li><a href="https://jina.ai/models/jina-embeddings-v5-text-small/">https://jina.ai/models/jina-embeddings-v5-text-small/</a></li>
</ul>
<hr />
<h2><a href="https://jules.google/docs/changelog/2026-02-19">Google Jules新增CI修复与提交署名</a> <code>#6</code></h2>
<blockquote>
<p><strong>Google</strong> 旗下 <code>AI Agent Jules</code> 发布更新，新增 <code>CI Fixer</code> 自动修复功能。</p>
</blockquote>
<p><strong>Google</strong> 旗下 <code>AI Agent</code> <strong>Jules</strong> 发布更新，新增 <code>CI Fixer</code> 自动修复功能及可配置的提交作者身份。据官方更新日志，<code>CI Fixer</code> 可自动检测并修复 <strong>Jules</strong> 所创建 <code>PR</code> 中 <code>GitHub Actions</code> 的失败检查，无需人工干预即可完成错误接收、修正及重新提交。同时，新增的 <code>Commit Authoring</code> 设置提供“<strong>Jules</strong>”、“<code>Co-authored</code>”及“<code>User only</code>”三种模式。该用户级设置适用于所有仓库，解决了此前因 <strong>Jules</strong> 独占署名导致用户 <strong>GitHub</strong> <code>GitHub 贡献图</code> 无法体现实际工作的问题。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/a0feab5f-5fb8-4cdd-8d14-8512625885be/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://jules.google/docs/changelog/2026-02-19">https://jules.google/docs/changelog/2026-02-19</a></li>
</ul>
<hr />
<h2><a href="https://huggingface.co/blog/unsloth-jobs">Hugging Face推出Coding Agent 免费微调模型功能</a> <code>#7</code></h2>
<blockquote>
<p><strong>Hugging Face</strong> 与 <strong>Unsloth</strong> 合作推出了基于 <code>Coding Agent</code> 的免费模型微调服务，用户可通过验证领取免费 <code>GPU</code> 额度及 <strong>Pro</strong> 订阅。</p>
</blockquote>
<p><strong>Hugging Face</strong> 联合 <strong>Unsloth</strong> 推出通过 <code>Coding Agent</code> <strong>免费</strong>微调模型的新功能。官方目前向加入“<strong>Unsloth Jobs Explorers</strong>”组织并验证账单的用户提供 <strong>免费</strong> <code>GPU</code> 额度及 <strong>一个月</strong> <strong>Pro</strong> 订阅。该方案利用 <strong>Unsloth</strong> 约 <strong>2</strong> 倍速度提升和 <strong>60%</strong> <code>显存</code> 优化，重点支持 <strong>1GB</strong> <code>内存</code> 以下的小型模型。核心亮点在于支持 <code>Claude Code</code> 或 <code>Codex</code> 根据自然语言指令自动生成 <code>脚本</code>、提交 <code>云端任务</code> 及监控进度。据 <strong>Unsloth</strong> 创始人透露，该合作还支持 <code>强化学习</code>，旨在通过全托管 <code>云端环境</code> 实现无基础设施设置的快速迭代。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/c47a3967-6713-441a-8f61-dbe1261be5de/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://huggingface.co/blog/unsloth-jobs">https://huggingface.co/blog/unsloth-jobs</a></li>
</ul>
<hr />
<h2><a href="https://x.com/OpenRouter/status/2024172341190938958">OpenRouter上线模型 Benchmarks 页面</a> <code>#8</code></h2>
<blockquote>
<p><strong>OpenRouter</strong> 正式上线 <code>Benchmarks</code> 页面，直观展示模型在 <code>编程</code>、<code>数学</code> 及 <code>长上下文推理</code> 等维度的行业标准测试表现。</p>
</blockquote>
<p><strong>OpenRouter</strong> 宣布正式上线 Benchmarks 页面，展示模型在编程、数学、科学及长上下文推理等维度的行业标准表现，并计划未来扩展测试项目。与此同时，Rankings 页面迎来更新，新增 Intelligence、Coding 和 Agentic Index scores 排行榜，支持模型变体对比，旨在优化模型筛选体验。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/1ef083f3-a97d-4b5f-adff-86a3e866a2f3/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/OpenRouter/status/2024172341190938958">https://x.com/OpenRouter/status/2024172341190938958</a></li>
<li><a href="https://openrouter.ai/rankings#bench">https://openrouter.ai/rankings#bench</a></li>
</ul>
<hr />
<h2><a href="https://github.com/cline/cline/security/advisories/GHSA-9ppg-jx86-fqw7">Cline CLI npm包遭遇供应链攻击</a> <code>#9</code></h2>
<blockquote>
<p><code>Cline CLI</code> 官方确认遭遇 <code>供应链攻击</code>，攻击者利用被盗的 <strong>npm</strong> <code>令牌</code> 发布了恶意版本 <code>cline@2.3.0</code>。</p>
</blockquote>
<p>据官方安全公告与<strong>Endor Labs</strong>报告确认，<code>Cline CLI</code>在<code>npm注册表</code>遭遇<code>供应链攻击</code>。未授权方利用被盗用的<code>发布令牌</code>，发布了恶意版本 <code>cline@2.3.0</code>。该版本通过篡改 <code>postinstall</code> 脚本，在用户机器上全局静默安装名为<code>OpenClaw</code>的程序。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/0c93aaf2-9d16-4edc-b97a-1ed1f00abcb9/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/cline/cline/security/advisories/GHSA-9ppg-jx86-fqw7">https://github.com/cline/cline/security/advisories/GHSA-9ppg-jx86-fqw7</a></li>
</ul>
<hr />
<h2><a href="https://x.com/OpenAIDevs/status/2024600394299822096">OpenAI优化ChatGPT交互式代码块</a> <code>#10</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 升级了 <code>ChatGPT</code> 的 <code>代码块功能</code>，实现了编写、编辑与预览的一体化交互。</p>
</blockquote>
<p><strong>OpenAI</strong> 优化了 <code>ChatGPT</code> 的 <code>Code Blocks</code> 功能，将代码编写、编辑与预览集成于同一交互组件。用户现可在对话流程中直接构建并实时预览微型应用与图表，改变了以往静态显示模式。此次更新加强了对流程图和 <code>Mermaid 图表</code> 的原生支持，并新增 <code>代码调试</code> 功能。同时，引入的 <code>分屏</code> 与 <code>全屏视图</code> 优化了审查体验。该功能作为原生 <code>UI</code> 的一部分，旨在简化从构思到实现的转换过程。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/32915a41-6c62-4111-a99a-c0107af63349/m001.gif" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/OpenAIDevs/status/2024600394299822096">https://x.com/OpenAIDevs/status/2024600394299822096</a></li>
</ul>
<hr />
<h2><a href="https://claude.com/claude-in-powerpoint">Anthropic 向 Pro 用户开放 Claude in PowerPoint</a> <code>#11</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 宣布，<code>Claude in PowerPoint</code> 功能现已支持 Pro 计划，该功能可实现演示文稿的高效自动化生成。</p>
</blockquote>
<p><strong>Anthropic</strong> 官方宣布，<code>Claude in PowerPoint</code> 现已支持 <strong>Pro</strong> 计划，此前该功能已向 <strong>Max</strong>、<strong>Team</strong> 及 <strong>Enterprise</strong> 客户开放。该集成允许 <code>Claude</code> 在 <code>PowerPoint</code> 中实时构建、编辑幻灯片，并严格遵循 <code>Slide Master</code> 及 <code>品牌指南</code>。</p>
<p>主要功能包括：支持基于企业模板或从零开始生成完整草稿；能在保留原有格式的前提下进行精准修改，并将项目符号转化为可编辑的原生图表；此外，该功能现已支持 <code>connectors</code>，可将日常工具中的上下文直接引入幻灯片，并在现有 <code>合规框架</code> 内工作。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/9f5cb49d-e83e-4799-82ee-e57eed83d9b0/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://claude.com/claude-in-powerpoint">https://claude.com/claude-in-powerpoint</a></li>
<li><a href="https://x.com/claudeai/status/2024550844998570324">https://x.com/claudeai/status/2024550844998570324</a></li>
</ul>
<hr />
<h2><a href="https://github.com/netease-youdao/LobsterAI">网易有道开源个人助理Agent LobsterAI</a> <code>#12</code></h2>
<blockquote>
<p><strong>网易有道</strong>在 <strong>GitHub</strong> 开源了全场景个人助理项目 <code>LobsterAI</code>。</p>
</blockquote>
<p><strong>网易有道</strong>在 <strong>GitHub</strong> 开源全场景个人助理项目 <strong>LobsterAI</strong>。该工具基于 <code>Claude Agent SDK</code>，通过 <code>Cowork</code> 模式实现 7×<strong>24</strong> 小时自主办公。它支持本地或 <strong>Alpine Linux</strong> 沙箱环境，内置 <strong>16</strong> 种技能涵盖数据分析、PPT 制作及 <code>Playwright</code> 自动化等，且具备记忆提取与定时任务能力。<strong>LobsterAI</strong> 兼容 <strong>macOS</strong>、<strong>Windows</strong> 及 <strong>Linux</strong>，支持通过 <strong>钉钉</strong>、<strong>飞书</strong> 等 IM 远程触发，数据本地 <code>SQLite</code> 存储，现已在 <strong>GitHub</strong> 提供源码及安装包。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/6246bbd0-ebd2-4f84-9735-93ec53450353/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/netease-youdao/LobsterAI">https://github.com/netease-youdao/LobsterAI</a></li>
</ul>
<hr />
<h2><a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/pomelli-photoshoot/">Google Labs发布Pomelli影棚级产品照功能</a> <code>#13</code></h2>
<blockquote>
<p><strong>Google Labs</strong>为<strong>免费</strong>营销工具<strong>Pomelli</strong>推出了<code>Photoshoot</code>功能，仅凭<strong>一张</strong>产品图就能自动生成符合品牌调性的专业级影棚照。目前已在美加澳新<strong>免费</strong>开放。</p>
</blockquote>
<p><strong>Google Labs</strong> 官方宣布为其<strong>免费</strong>营销工具 <strong>Pomelli</strong> 推出<code>Photoshoot</code>功能，旨在利用<code>Business DNA</code>和<code>Nano Banana</code>技术，协助中小企业及个人用户通过<strong>四步</strong>操作将单张产品图转化为符合品牌调性的专业级影棚照。用户仅需上传图片、选择模板、生成并微调，即可获得高质量图像。除核心功能外，<strong>Pomelli</strong> 还同步升级了图像生成模型，提升了准确性；新增了图像编辑及风格参考功能；在营销活动创建上，支持基于 URL 的上下文生成。目前该工具已在美国、加拿大、澳大利亚和新西兰<strong>免费</strong>开放。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/47df0fbd-b4db-40d5-87c2-ba63b0d0ffce/m001.gif" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/innovation-and-ai/models-and-research/google-labs/pomelli-photoshoot/">https://blog.google/innovation-and-ai/models-and-research/google-labs/pomelli-photoshoot/</a></li>
<li><a href="https://x.com/GoogleLabs/status/2024529795548102667">https://x.com/GoogleLabs/status/2024529795548102667</a></li>
</ul>
<hr />
<h2><a href="https://x.com/NotebookLM/status/2024585603703329259">NotebookLM发布幻灯片修订及PPTX导出</a> <code>#14</code></h2>
<blockquote>
<p><code>NotebookLM</code>现已向所有用户开放<code>PPTX</code>导出权限，免费用户也即将上线基于提示词的幻灯片调整功能。</p>
</blockquote>
<p><code>**NotebookLM**</code>官方宣布<code>Slide Revisions</code>功能已向所有付费用户推出，免费用户即将获支持；<code>PPTX</code>导出功能现已面向<code>**100%**</code>用户开放。此次核心更新<code>Prompt-Based Revisions</code>允许通过<code>提示词</code>微调幻灯片。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/14ea0454-45ec-44fb-b11c-7af0215def96/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/NotebookLM/status/2024585603703329259">https://x.com/NotebookLM/status/2024585603703329259</a></li>
</ul>
<hr />
<h2><a href="https://support.google.com/youtube/thread/18138167?hl=en">YouTube扩展对话式AI至电视平台</a> <code>#15</code></h2>
<blockquote>
<p><strong>YouTube</strong> 已将 <code>对话式 AI 工具</code> 扩展至智能电视及流媒体设备，允许成年用户在不中断视频观看的情况下实时提问并获得解答。</p>
</blockquote>
<p><strong>YouTube</strong> 宣布将其 <code>对话式 AI 工具</code> 作为实验性功能扩展至 <code>智能电视</code>、<code>游戏主机</code>及 <code>流媒体设备</code>。该功能允许部分 <strong>18</strong> 岁以上选定用户，通过 <code>遥控器麦克风</code> 或“Ask”按钮，在不中断视频播放的情况下提问并获得即时解答，目前支持英语等 <strong>五种</strong> 语言。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://support.google.com/youtube/thread/18138167?hl=en">https://support.google.com/youtube/thread/18138167?hl=en</a></li>
</ul>
<hr />
<h2><a href="https://openai.com/index/advancing-independent-research-ai-alignment/">OpenAI向AI对齐研究基金捐赠 750 万美元</a> <code>#16</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 宣布向 <strong>英国 AI 安全研究所</strong> 设立的独立研究基金 <strong>The Alignment Project</strong> 捐赠 <strong>750 万美元</strong>，以支持全球范围内的 <code>AI 对齐</code> 与 <code>AI 安全</code> 研究。</p>
</blockquote>
<p><strong>OpenAI</strong>宣布向由<strong>英国AI安全研究所（UK AISI）<strong>创建的独立基金</strong>The Alignment Project</strong>捐赠<strong>750万美元</strong>（约<strong>560万英镑</strong>）。该基金总额超<strong>2700万英镑</strong>，由<strong>Renaissance Philanthropy</strong>协助管理，重点资助<code>计算复杂性</code>、<code>博弈论</code>等领域的全球独立研究以缓解<code>AI风险</code>。单个项目资助额度通常在<strong>5万</strong>至<strong>100万英镑</strong>之间。<strong>OpenAI</strong>强调，此次注资旨在增加当前轮次已通过审查的高质量项目数量，而非干预现有流程，以支持与内部前沿研究互补的外部独立生态，确保<code>AGI</code>的安全性。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/a2ce6d67-a4f0-49fd-9afe-b39c7a6664e4/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://openai.com/index/advancing-independent-research-ai-alignment/">https://openai.com/index/advancing-independent-research-ai-alignment/</a></li>
</ul>
<hr />
<h2><a href="https://openai.com/openai-for-india/">OpenAI联手塔塔集团布局印度市场</a> <code>#17</code></h2>
<blockquote>
<p><strong>OpenAI</strong>与印度<strong>Tata集团</strong>达成战略合作，成为其数据中心的客户，首批锁定<strong>100MW</strong>容量并计划扩展至<strong>1GW</strong>，而<strong>Tata集团</strong>将在内部部署<code>ChatGPT Enterprise</code>。</p>
</blockquote>
<p>据媒体报道，<strong>OpenAI</strong>与印度<strong>Tata Group</strong>达成战略合作。<strong>OpenAI</strong>将成为<strong>TCS</strong>旗下<code>HyperVault</code>数据中心业务的首个客户，初步锁定<strong>100MW</strong>容量并计划扩展至<strong>1GW</strong>，以满足印度<code>数据驻留</code>及<code>低延迟</code>需求。双方还将在<strong>Tata集团</strong>内部署<code>ChatGPT Enterprise</code>覆盖数十万员工，并利用<code>Codex</code>工具标准化软件开发。此外，<strong>OpenAI</strong>计划<strong>今年晚些时候</strong>在孟买和班加罗尔设立新办事处，并将扩展认证项目，<strong>TCS</strong>将成为美国以外首个参与该项目的组织。据官方引用CEO <strong>Sam Altman</strong>估算，印度目前拥有超<strong>1亿</strong><code>ChatGPT</code>周活跃用户。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://openai.com/openai-for-india/">https://openai.com/openai-for-india/</a></li>
<li><a href="https://techcrunch.com/2026/02/18/openai-taps-tata-for-100mw-ai-data-center-capacity-in-india-eyes-1gw">https://techcrunch.com/2026/02/18/openai-taps-tata-for-100mw-ai-data-center-capacity-in-india-eyes-1gw</a></li>
</ul>
<hr />
<h2><a href="https://www.ft.com/content/dffe72d0-4064-4412-8ebc-50198a30d40e">传Ineffable寻求十亿美元种子轮融资</a> <code>#18</code></h2>
<blockquote>
<p>据报道，<code>AlphaGo</code>核心贡献者<strong>David Silver</strong>创立的<strong>Ineffable Intelligence</strong>正在筹集约<strong>10亿美元</strong><code>种子轮融资</code>，<strong>红杉资本</strong>领投，投前估值高达<strong>40亿美元</strong>。</p>
</blockquote>
<p>据<strong>金融时报</strong>报道，<code>AlphaGo</code>核心贡献者、前<strong>Google</strong> <strong>DeepMind</strong>资深研究员<strong>David Silver</strong>正在为伦敦初创公司<strong>Ineffable Intelligence</strong>筹集约<strong>10亿美元</strong>种子轮融资，由<strong>红杉资本</strong>领投，投前估值约<strong>40亿美元</strong>。若交易完成，这将创下欧洲史上最大种子轮融资纪录。据悉，<strong>英伟达</strong>、<strong>Google</strong>和<strong>微软</strong>也正参与谈判。</p>
<p>该公司致力于构建“无尽学习的超级智能”，其技术路径不同于主流<code>LLM</code>，而是基于Silver在<code>强化学习</code>领域的积累，利用<code>世界模型</code>在模拟环境中通过试错和自主经验持续进化。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.ft.com/content/dffe72d0-4064-4412-8ebc-50198a30d40e">https://www.ft.com/content/dffe72d0-4064-4412-8ebc-50198a30d40e</a></li>
</ul>
<hr />
<h2><a href="https://www.anthropic.com/research/measuring-agent-autonomy">Anthropic发布关于AI Agent自主性的实证研究报告</a> <code>#19</code></h2>
<blockquote>
<p><strong>Anthropic</strong>发布关于<code>AI Agent</code>自主性的实证研究报告，报告指出，用户信任积累使Agent单次自主运行时长已增长至<strong>45分钟</strong>以上。</p>
</blockquote>
<p><strong>Anthropic</strong>发布**《Measuring AI agent autonomy in practice》<strong>报告显示，<code>Agent</code>自主性取得显著进展。过去三个月内，<code>Claude Code</code>单次免干预最长运行时间从</strong>不到25分钟<strong>增至</strong>超过45分钟**，主要归因于用户信任度提升。在监督模式上，资深开发者相比新手更倾向全自动批准（<strong>超40%</strong> vs <strong>20%</strong>），但主动打断频率也更高（<strong>9%</strong> vs <strong>5%</strong>），体现了“充分放权但保持敏锐监控”的策略。此外，<code>Agent</code>在复杂任务中主动求助次数是人类打断次数的<strong>两倍多</strong>，确立了关键的安全机制。目前<strong>近半数</strong><code>Agent</code>操作集中在软件工程低风险领域，医疗、金融等高危行业虽已探索，但距离<code>规模化部署</code>尚有距离。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/b4168262-a53a-4f59-9516-4ae46025221b/m001.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/b4168262-a53a-4f59-9516-4ae46025221b/m002.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/research/measuring-agent-autonomy">https://www.anthropic.com/research/measuring-agent-autonomy</a></li>
</ul>
<hr />
<h2><a href="https://www.youtube.com/watch?v=lieqoaBV6ww">强化学习奠基人Sutton提出经验时代论</a> <code>#20</code></h2>
<blockquote>
<p><strong>图灵奖</strong>得主<strong>理查德·萨顿</strong>发表**《AI 的未来》**演讲，指出当前依赖人类数据的<code>大模型</code>仅是缺乏理解的<code>弱心智</code>，且正面临<code>数据枯竭</code>的天花板。让<code>智能体</code>通过与真实环境交互产生的<code>数据流</code>进行<code>持续学习</code>，是实现<code>超级智能</code>的必由之路。</p>
</blockquote>
<p>图灵奖得主、<code>强化学习</code>奠基人<strong>Richard Sutton</strong>近日在洛杉矶加州大学纯粹与应用数学研究所（IPAM）发表了题为《AI的未来》的演讲。<strong>Sutton</strong>直指当前基于人类数据训练的<code>大模型</code>仅为“弱心智”，虽拥有海量知识但缺乏理解与真值判断能力。他称这种智能的本质是“理解太少、调参太多”，并认为AI正面临人类高质量数据枯竭的天花板。</p>
<p><strong>Sutton</strong>提出，AI的未来属于“<code>经验时代</code>”。其核心是让<code>AI Agent</code>通过与环境的交互，从持续的经验流中学习，而非依赖静态的人类数据集。他指出，经验数据能随Agent能力提升而增长，这是实现突破、创造新知识的必由之路。他将过去十年划分为<code>模拟时代</code>、<code>人类数据时代</code>，以及正在开启的<code>经验时代</code>。</p>
<p>在政治与哲学层面，<strong>Sutton</strong>呼吁抵制对AI的集中控制，主张<code>去中心化合作</code>。他进一步提出宏大的宇宙演化视角，认为宇宙正进入“<code>设计时代</code>”，人类作为“<code>复制者</code>”的极限，其使命是创造具有设计能力的心智——即AI。因此，人类在这一进程中扮演着催化剂与先驱的角色，而资源与权力最终将流向更具智能的存在。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=lieqoaBV6ww">https://www.youtube.com/watch?v=lieqoaBV6ww</a></li>
<li><a href="https://mp.weixin.qq.com/s/N773VlnwHkUA-hNKRI_YtA">https://mp.weixin.qq.com/s/N773VlnwHkUA-hNKRI_YtA</a></li>
</ul>
<hr />
<h2><a href="https://x.com/testingcatalog/status/2024492284184563899">传OpenAI正开发ChatGPT成人模式</a> <code>#21</code></h2>
<blockquote>
<p>有用户在<code>ChatGPT</code>网页代码中发现，<strong>OpenAI</strong>疑似正在开发代号为<code>Citron Mode</code>的成人模式。</p>
</blockquote>
<p>据媒体报道，<strong>OpenAI</strong> 正在为 <code>ChatGPT</code> 开发 <code>成人模式</code>。开发者 <strong>Tibor Blaho</strong> 在其 <code>网页代码</code> 中发现了内部代号为 <code>Citron Mode</code> 的设置，据推测即为此功能。该模式引入 <code>敏感内容警告机制</code>，当用户分享被标记为 <code>citron-only</code> 的对话时，系统将显示警告，提示接收者可能需要验证年满 <strong>18岁</strong> 才能查看内容。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/f96fac1c-7916-4cdd-871b-23b35f1671b5/m001.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/16360009-d4cc-45fa-93d8-348cb1cb3b6c/f96fac1c-7916-4cdd-871b-23b35f1671b5/m002.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/testingcatalog/status/2024492284184563899">https://x.com/testingcatalog/status/2024492284184563899</a></li>
<li><a href="https://x.com/TiborBlaho">https://x.com/TiborBlaho</a></li>
</ul>
<hr />
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content><link href="https://github.com/imjuya/juya-ai-daily/issues/3"/><published>2026-02-20T01:01:35+00:00</published></entry><entry><id>https://github.com/imjuya/juya-ai-daily/issues/2</id><title>2026-02-19</title><updated>2026-02-22T01:00:46.813824+00:00</updated><content type="html"><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260219/20260219090351005487a008_cover_73fa.png" alt="" /></p>
<h1>AI 早报 2026-02-19</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=qaQ1uDPjCqk">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1WfZ8BqEu6">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>模型发布</h3>
<ul>
<li>Google DeepMind发布Lyria 3音乐生成模型 <code>#1</code></li>
<li>xAI 发布16-Agent协作模式 Grok 4.20 Heavy <code>#2</code></li>
<li>Prime Intellect开源106B参数MoE模型 <code>#3</code></li>
<li>印度AI企业Sarvam发布Sarvam-30B与105B <code>#4</code></li>
</ul>
<h3>开发生态</h3>
<ul>
<li>OpenAI 开源 Codex App Server 支持ChatGPT登录 <code>#5</code></li>
<li>Figma 推出 Claude Code to Figma 功能 <code>#6</code></li>
<li>OpenAI发布智能合约安全基准EVMbench <code>#7</code></li>
<li>Gemini CLI 推出 v0.29.0 版本每周更新 <code>#8</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>谷歌、OpenAI 和微软宣布在印计划 <code>#9</code></li>
<li>Perplexity撤下搜索平台广告 <code>#10</code></li>
<li>World Labs完成融资并与Autodesk合作 <code>#11</code></li>
</ul>
<h3>技术与洞察</h3>
<ul>
<li>智谱AI发布GLM-5技术报告 <code>#12</code></li>
</ul>
<hr />
<h2><a href="https://deepmind.google/models/lyria/">Google DeepMind发布Lyria 3音乐生成模型</a> <code>#1</code></h2>
<blockquote>
<p><strong>Google DeepMind</strong> 发布音乐生成模型 <code>Lyria 3</code>，并已在 <code>Gemini</code> 桌面端开启测试。用户只需输入文字描述或上传图片、视频，即可生成 <strong>30 秒</strong> 带歌词的 <code>高保真</code> 音乐，且支持对风格和人声的精细控制。该功能面向 <strong>18 岁</strong> 以上用户开放，生成的所有音轨均嵌入 <code>SynthID</code> 水印，以确保可追溯性。</p>
</blockquote>
<p><strong>Google DeepMind</strong> 发布最先进音乐生成模型 <strong>Lyria 3</strong>，并已在 <strong>Gemini App</strong> 中推出 Beta 版。用户可以通过 <code>文本转音轨</code> 功能，描述特定的流派、情绪、记忆甚至内部笑话来生成音乐；也可以利用 <code>图像/视频转音轨</code> 功能，上传照片或视频，让 AI 根据视觉内容的氛围自动谱曲并填写歌词。<strong>Gemini App</strong> 生成的音轨时长固定为 <strong>30</strong> 秒，并附带由 <code>Nano Banana</code> 生成的自定义封面图。</p>
<p>官方指出，<strong>Lyria 3</strong> 的 <strong>三大</strong> 改进点包括：自动生成歌词无需用户提供、提供对风格及人声和节奏的更强控制、以及生成更真实且音乐结构更复杂的曲目。该服务目前向所有 <strong>18</strong> 岁及以上的 <strong>Gemini</strong> 用户开放，支持英语、德语、西班牙语、法语、印地语、日语、韩语和葡萄牙语。桌面端现已可用，移动端预计将在未来几天内上线，<strong>Google AI Plus</strong>、<strong>Pro</strong> 和 <strong>Ultra</strong> 订阅用户将享有更高的使用额度。在 <strong>Gemini</strong> 应用中生成的所有音轨均嵌入了 <code>SynthID</code>，<strong>Gemini</strong> 亦上线了 <code>音频验证工具</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/f050b0b0-bd7f-4176-b7e3-b545c975855d/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://deepmind.google/models/lyria/">https://deepmind.google/models/lyria/</a></li>
<li><a href="https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/">https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/</a></li>
</ul>
<hr />
<h2><a href="https://x.com/elonmusk/status/2024194618930401590">xAI 发布16-Agent协作模式 Grok 4.20 Heavy</a> <code>#2</code></h2>
<blockquote>
<p><strong>Elon Musk</strong> 宣布<strong>xAI</strong>上线 <code>Grok 4.20 Heavy</code> 并向 Heavy 订阅用户开放。该模型核心架构为由 <strong>16</strong> 个专门化 <code>Agent</code> 组成的协作团队。</p>
</blockquote>
<p><strong>Elon Musk</strong>宣布推出<code>Grok 4.20 Heavy</code>，称其为重大升级，现已向<strong>Heavy</strong>订阅者开放。该版本核心变化在于底层架构调整，即在<code>grok-4.20架构</code>下运行由<strong>16</strong>个专门化<code>Agent</code>组成的团队进行<code>实时协作</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/e0145bc4-033f-4528-bfb5-5821485d31b6/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/elonmusk/status/2024194618930401590">https://x.com/elonmusk/status/2024194618930401590</a></li>
<li><a href="https://x.com/tetsuoai/status/2024121909286494435">https://x.com/tetsuoai/status/2024121909286494435</a></li>
</ul>
<hr />
<h2><a href="https://huggingface.co/PrimeIntellect/INTELLECT-3.1">Prime Intellect开源106B参数MoE模型</a> <code>#3</code></h2>
<blockquote>
<p><strong>Prime Intellect</strong> 发布了基于 <code>GLM-4.5-Air-Base</code> 通过 <code>强化学习</code> 训练的 <code>INTELLECT-3.1</code> 模型，显著提升了在数学、编程及 <code>Agent</code> 任务上的表现。</p>
</blockquote>
<p><strong>Prime Intellect</strong> 发布开源推理模型 <code>INTELLECT-3.1</code>。该模型采用 <code>Mixture-of-Experts (MoE)</code> 架构，拥有 <strong>106B</strong> 总参数及 <strong>A12B</strong> 活跃参数，基于 <code>zai-org/GLM-4.5-Air-Base</code> 并结合 <code>prime-rl</code> 框架进行了强化学习训练，重点提升了数学、编程、软件工程和 <code>Agent</code> 任务的能力。</p>
<p>官方已将模型、训练框架及环境以 <code>MIT</code> 和 <code>Apache 2.0</code> 协议完全开源，并提供了技术报告。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://huggingface.co/PrimeIntellect/INTELLECT-3.1">https://huggingface.co/PrimeIntellect/INTELLECT-3.1</a></li>
</ul>
<hr />
<h2><a href="https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai">印度AI企业Sarvam发布Sarvam-30B与105B</a> <code>#4</code></h2>
<blockquote>
<p>印度AI初创公司<strong>Sarvam</strong>发布了从零训练的<code>Sarvam-30B</code>和<code>Sarvam-105B</code>混合专家架构模型。根据官方数据，这两款模型针对印度本土语言进行了优化，在多项基准测试中表现出色。</p>
</blockquote>
<p>印度AI初创公司<strong>Sarvam</strong>近日发布了<strong>两款</strong>从零训练的<code>大型语言模型``Sarvam-30B</code>和<code>Sarvam-105B</code>，并同步推出语音及视觉模型。核心模型采用<code>混合专家架构</code>，获<strong>印度政府</strong>、<strong>Yotta</strong>及<strong>Nvidia</strong>支持。其中，<strong>30B</strong>模型预训练数据达<strong>16T</strong> <code>Token</code>，支持<strong>32k</strong> <code>上下文</code>；<strong>105B</strong>模型支持<strong>128k</strong> <code>上下文</code>，专攻复杂推理。官方数据显示，其性能优于或持平<code>Gemma</code>、<code>Qwen</code>等竞品。<strong>Sarvam</strong>计划开源<strong>这两款</strong>模型，并推出**“Sarvam for Work”<strong>企业工具及</strong>“Samvaad”**对话<code>Agent</code>平台。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/d06d1a70-4751-4a0e-a57a-33b53050c804/m001.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/d06d1a70-4751-4a0e-a57a-33b53050c804/m002.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai">https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai</a></li>
</ul>
<hr />
<h2><a href="https://developers.openai.com/codex/app-server/">OpenAI 开源 Codex App Server 支持ChatGPT登录</a> <code>#5</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 开源了驱动 Codex 应用的底层框架 <code>Codex App Server</code>，允许开发者将 <code>Codex Agent</code> 深度集成到自有产品中。该工具支持通过 <strong>ChatGPT</strong> 账号 <code>OAuth</code> 直接接入第三方应用。</p>
</blockquote>
<p><strong>OpenAI</strong> 已开源其核心接口 <code>Codex App Server</code>，旨在让开发者在自有产品中深度集成 <code>Codex Agent</code>。该服务器是 Codex 富客户端（如 <code>VS Code</code> 扩展）的底层驱动，支持通过 <strong>ChatGPT</strong> 账号 <code>OAuth</code> 直接接入第三方应用，并提供身份验证、会话历史、审批流和流式 Agent 事件等完整功能。在协议层面，其采用类似 <code>MCP</code> 的 <code>JSON-RPC 2.0</code> 进行双向通信，支持 <code>stdio</code> 和实验性的 <code>websocket</code> 传输方式。客户端必须在连接后立即发送 <code>initialize</code> 请求并携带标识信息，企业级集成需在 <strong>OpenAI</strong> 平台注册。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/f1458b74-fc09-407d-9990-8504ee226fb2/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://developers.openai.com/codex/app-server/">https://developers.openai.com/codex/app-server/</a></li>
<li><a href="https://github.com/openai/codex/tree/main/codex-rs/app-server">https://github.com/openai/codex/tree/main/codex-rs/app-server</a></li>
</ul>
<hr />
<h2><a href="https://www.figma.com/blog/introducing-claude-code-to-figma/">Figma 推出 Claude Code to Figma 功能</a> <code>#6</code></h2>
<blockquote>
<p><strong>Figma</strong> 近期推出 <code>Claude Code to Figma</code> 功能，利用 <code>Figma MCP Server</code>，能够将 <code>Claude Code</code> 生成的 <code>UI</code> 直接转化为 <strong>Figma</strong> 画布上的可编辑 <code>Frame</code>。</p>
</blockquote>
<p><strong>Figma</strong> 近期推出“<code>Claude Code</code> to <strong>Figma</strong>”功能，通过更新<strong>Figma</strong><code>MCP server</code>，打通代码构建与设计协作。开发者可将<code>Claude Code</code>生成的真实<code>UI</code>转化为<strong>Figma</strong>画布上可编辑的<code>Frame</code>，支持捕捉完整流程并保留上下文，从而实现从“代码收敛”到“画布发散”的高效转换。该功能允许团队直接对代码生成的界面进行协作，避免了截图反馈的摩擦，并支持从设计回到代码的“往返”工作流。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/1aadc184-cda8-4630-858b-7a5f6b3a2db2/m001.gif" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.figma.com/blog/introducing-claude-code-to-figma/">https://www.figma.com/blog/introducing-claude-code-to-figma/</a></li>
</ul>
<hr />
<h2><a href="https://openai.com/index/introducing-evmbench/">OpenAI发布智能合约安全基准EVMbench</a> <code>#7</code></h2>
<blockquote>
<p><strong>OpenAI</strong> 与 <strong>Paradigm</strong> 联合推出了<code>智能合约安全基准</code> <code>EVMbench</code>，旨在评估 <code>AI Agent</code> 在检测、修补及利用高危漏洞方面的<code>实战能力</code>。</p>
</blockquote>
<p><strong>OpenAI</strong> 联合 <strong>Paradigm</strong> 发布 <code>EVMbench</code> 基准，旨在评估 <code>AI Agent</code> 在 <code>智能合约</code> 安全领域（<code>检测</code>、<code>修补</code>、<code>利用</code>）的能力。该基准包含 <strong>120</strong> 个源自 <strong>40</strong> 次审计的漏洞场景，并配备基于 <code>Rust</code> 的测试工具和 <code>隔离沙盒</code> 环境。</p>
<p>官方评估显示，<code>GPT-5.3-Codex</code> 在 <code>Exploit</code> 模式得分 <strong>72.2%</strong>，显著优于 <code>GPT-5</code> 的 <strong>31.9%</strong>，但在 <code>检测</code> 和 <code>修补</code> 方面仍有提升空间。<strong>OpenAI</strong> 承认该基准存在环境与评分机制局限，不完全代表现实难度。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://openai.com/index/introducing-evmbench/">https://openai.com/index/introducing-evmbench/</a></li>
</ul>
<hr />
<h2><a href="https://github.com/google-gemini/gemini-cli/discussions/19473">Gemini CLI 推出 v0.29.0 版本每周更新</a> <code>#8</code></h2>
<blockquote>
<p><code>Gemini CLI</code> 推出 <code>v0.29.0</code> 版本更新，新增 <code>Ask User Tool</code> 支持模型交互式提问以澄清指令，同时引入 <code>Conductor</code> 和 <code>Firebase Agent Skills</code> 扩展，并上线了实验性 <code>Plan Mode</code>。</p>
</blockquote>
<p><strong>Gemini CLI</strong> 近日推出 <strong>v0.29.0</strong> 版本更新，新增 <code>Ask User Tool</code>，支持模型交互式暂停并询问用户以获取澄清。官方扩展了生态系统，引入 <strong>Conductor</strong> 扩展用于自动化逻辑审查与合规报告，以及 <strong>Firebase Agent Skills</strong> 扩展以优化开发体验。性能方面，更新优化了对海量工具输出的处理，防止 <code>上下文窗口</code> 过载，从而支持更长时间的高质量推理；同时改进了 <code>Vim</code> 编辑体验（支持 <code>W</code>、<code>B</code>、<code>E</code> 动作）及快捷键可发现性（按 <code>?</code> 唤起）。此外，官方首推实验性 <code>Plan Mode</code>，该只读模式旨在帮助用户在不修改文件的前提下映射代码库并验证假设。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/google-gemini/gemini-cli/discussions/19473">https://github.com/google-gemini/gemini-cli/discussions/19473</a></li>
</ul>
<hr />
<h2><a href="https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/">谷歌、OpenAI 和微软宣布在印计划</a> <code>#9</code></h2>
<blockquote>
<p>在新德里 <code>AI Impact Summit</code> 上，<strong>谷歌</strong>、<strong>OpenAI</strong> 和 <strong>微软</strong> 密集公布了它们在印度的最新计划。<strong>谷歌</strong>启动了连接美印的<code>战略光纤倡议</code>；<strong>OpenAI</strong> 联合当地顶尖高校，将 <code>ChatGPT Edu</code> 引入高等教育体系；<strong>微软</strong> 则承诺在印度培训 <strong>2000 万人</strong>。</p>
</blockquote>
<p>本周在新德里<strong>AI Impact Summit</strong>期间，<strong>Google</strong>、<strong>OpenAI</strong>和<strong>Microsoft</strong>密集公布在印扩展计划。<strong>Google</strong>启动“<strong>America-India Connect</strong>”光缆基建倡议，连接美印及南半球；<strong>Google.org</strong>投入共<strong>6000万美元</strong>用于科学及政府创新挑战赛，并深化在教育、农业及能源领域的<code>AI模型</code>部署。<strong>OpenAI</strong>通过与印度顶尖高校合作，将<code>ChatGPT Edu</code>整合进高等教育体系，覆盖逾<strong>10万</strong>师生。<strong>Microsoft</strong>宣布到本十年末向“<strong>全球南方</strong>”投资<strong>500亿美元</strong>，其中计划在<strong>2030年</strong>前培训<strong>2000万</strong>印度人。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/">https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/</a></li>
<li><a href="https://techcrunch.com/2026/02/18/openai-pushes-into-higher-education-as-india-seeks-to-scale-ai-skills">https://techcrunch.com/2026/02/18/openai-pushes-into-higher-education-as-india-seeks-to-scale-ai-skills</a></li>
</ul>
<hr />
<h2><a href="https://www.ft.com/content/6eec07a5-34a8-4f78-a9ed-93ab4263d43c">Perplexity撤下搜索平台广告</a> <code>#10</code></h2>
<blockquote>
<p>据报道，<strong>Perplexity</strong>将撤下平台所有广告，以确保用户信任和搜索准确性。公司战略重心现已转向订阅服务和企业销售，并计划积极扩充销售团队。</p>
</blockquote>
<p>据报道，AI 搜索初创公司 <strong>Perplexity</strong> 将从平台撤下广告，以维护用户信任，坚持“准确性企业”定位。该公司高管表示不会在聊天机器人答案中投放广告，未来将专注于订阅服务和企业销售。公司目前正锁定大型企业及财务、医疗等高端用户，企业销售计划积极扩张。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.ft.com/content/6eec07a5-34a8-4f78-a9ed-93ab4263d43c">https://www.ft.com/content/6eec07a5-34a8-4f78-a9ed-93ab4263d43c</a></li>
</ul>
<hr />
<h2><a href="https://www.worldlabs.ai/blog/funding-2026">World Labs完成融资并与Autodesk合作</a> <code>#11</code></h2>
<blockquote>
<p><strong>李飞飞</strong>创立的 <strong>World Labs</strong> 宣布完成 <strong>10亿美元</strong> 新一轮融资，<strong>AMD</strong> 和 <strong>英伟达</strong> 等巨头参投。与此同时，<strong>Autodesk</strong>向其投入 <strong>2亿美元</strong> 并达成战略合作，计划将 <strong>World Labs</strong> 的 <code>空间智能模型</code> 与自家的 <code>3D 工具</code> 相结合。</p>
</blockquote>
<p><strong>李飞飞</strong>创立的AI初创公司<strong>World Labs</strong>近日宣布完成<strong>10亿美元</strong>新一轮融资，本轮融资由<strong>AMD</strong>、<strong>Autodesk</strong>、<strong>NVIDIA</strong>等机构共同参与。<strong>World Labs</strong>致力于通过构建<code>World Models</code>来推进空间智能发展。</p>
<p>软件设计巨头<strong>Autodesk</strong>在本轮融资中投资了<strong>2亿美元</strong>，并与<strong>World Labs</strong>达成战略合作。双方初期将聚焦于媒体和娱乐领域，探索将<strong>World Labs</strong>的模型与<strong>Autodesk</strong>的<code>3D工具</code>及正在开发的新一代生成式AI模型<code>Neural CAD</code>相结合，旨在为设计、建筑及娱乐行业提供更高级的物理AI解决方案。据<strong>Autodesk</strong>首席科学家<strong>Daron Green</strong>称，合作尚处早期阶段，且双方协议明确不包含数据共享。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.worldlabs.ai/blog/funding-2026">https://www.worldlabs.ai/blog/funding-2026</a></li>
</ul>
<hr />
<h2><a href="https://arxiv.org/abs/2602.15763">智谱AI发布GLM-5技术报告</a> <code>#12</code></h2>
<blockquote>
<p><strong>智谱AI</strong>在arXiv发布了<code>GLM-5</code>技术报告。该模型采用<code>DSA架构</code>，并已适配<strong>7种</strong>国产芯片。官方宣称，通过<code>异步Agent RL基础设施</code>及<code>Slime RL工具包</code>等创新， <code>GLM-5</code> 在开源模型中实现了<code>SOTA性能</code>。</p>
</blockquote>
<p><strong>智谱AI</strong>近日在<strong>arXiv</strong>上发布<code>GLM-5</code>技术报告，详述其架构与训练细节。该模型采用<code>DSA</code>架构，拥有<strong>750B</strong>总参数与<strong>40B</strong>激活参数，训练数据量达<strong>30T</strong>，并已完成对<strong>7</strong>种国产芯片的适配。</p>
<p>报告揭示了多项核心创新。<code>DSA</code>架构旨在降低训练推理成本并保持长上下文保真度。模型引入<code>Slime RL</code>工具包与<code>异步Agent RL</code>基础设施，通过解耦生成与训练过程提升后训练效率。技术实现细节上，<code>GLM-5</code>的<code>RL</code>算法使用了带有双向<code>Token级掩码</code>的<code>GRPO</code>。为提升效率，系统采用<code>FP8</code>减少Token间延迟，实施平均接受长度为<strong>2.76</strong>的<code>多Token预测</code>，并利用<code>数据并行感知路由</code>最大化<code>KV-cache</code>复用。此外，<code>Prefill-Decode分离技术</code>可避免处理干扰。其<code>异步Agent RL</code>系统基于样本阈值更新模型，会主动丢弃过旧或崩溃环境的样本，并通过<code>Token-in Token-out</code>机制对齐推理与训练，<code>混合式奖励系统</code>则衡量基础正确性、情商与任务质量。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/f93b154d-a72b-4e76-8770-06eec166737e/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://arxiv.org/abs/2602.15763">https://arxiv.org/abs/2602.15763</a></li>
<li><a href="https://x.com/Zai_org/status/2023951884826849777">https://x.com/Zai_org/status/2023951884826849777</a></li>
</ul>
<hr />
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content><link href="https://github.com/imjuya/juya-ai-daily/issues/2"/><published>2026-02-19T01:57:23+00:00</published></entry><entry><id>https://github.com/imjuya/juya-ai-daily/issues/1</id><title>2026-02-18</title><updated>2026-02-22T01:00:47.030191+00:00</updated><content type="html"><![CDATA[<p><img src="http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260218/202602180850442485579dde_cover_e48a.jpg" alt="" /></p>
<h1>AI 早报 2026-02-18</h1>
<p><strong>视频版</strong>：<a href="https://www.youtube.com/watch?v=8jAigWfpDKU">YouTube</a> ｜ <a href="https://www.bilibili.com/video/BV1uAZDBiEKF">哔哩哔哩</a></p>
<h2>概览</h2>
<h3>精选</h3>
<ul>
<li>Anthropic 发布 Claude Sonnet 4.6 <code>#1</code></li>
<li>xAI 上线 Grok 4.20 测试版 <code>#2</code></li>
<li>NotebookLM推出幻灯片Prompt修订与PPTX导出 <code>#3</code></li>
</ul>
<h3>模型发布</h3>
<ul>
<li>蚂蚁集团开源Ming-omni-tts音频生成模型 <code>#4</code></li>
<li>Cohere Labs发布Tiny Aya多语言模型 <code>#5</code></li>
<li>字节跳动研究团队开源 BitDance 多模态模型 <code>#6</code></li>
</ul>
<h3>开发生态</h3>
<ul>
<li>Cursor 发布 2.5 版本更新，推出插件市场 <code>#7</code></li>
<li>OpenAI修复GPT-5.3-Codex请求重定向问题 <code>#8</code></li>
<li>Cerebras下调部分免费层级的推理额度 <code>#9</code></li>
<li>Intelligent Internet 开源多Agent协作系统 Common Ground Core <code>#10</code></li>
</ul>
<h3>行业动态</h3>
<ul>
<li>Nerve加入OpenAI构建ChatGPT搜索 <code>#11</code></li>
<li>传 Moonshot AI 完成7亿美元融资 <code>#12</code></li>
</ul>
<hr />
<h2><a href="https://www.anthropic.com/news/claude-sonnet-4-6">Anthropic 发布 Claude Sonnet 4.6</a> <code>#1</code></h2>
<blockquote>
<p><strong>Anthropic</strong> 正式发布了 <code>Claude Sonnet 4.6</code> 模型。该模型在编程、长上下文推理及 <code>Agent</code> 规划能力上全面升级，并支持 <strong>100 万</strong> <code>token</code> 上下文。同步推出的还有改进版网页搜索工具，在提升准确率的同时大幅降低了 <code>Token</code> 消耗。目前，<code>Sonnet 4.6</code> 已上线 <code>API</code> 及各类AI应用，价格与上一代保持一致，免费版用户现已可在<strong>Claude</strong>体验。</p>
</blockquote>
<p><strong>Anthropic</strong> 正式发布 <code>Claude Sonnet 4.6</code>，官方称其为迄今最强的 <code>Sonnet</code> 模型。该模型在编程、长上下文推理、<code>Agent</code> 规划、知识工作及设计等领域全面升级，并提供支持 <strong>100 万</strong> token 的上下文窗口（<code>Beta版</code>）。价格维持每百万 token 输入 <strong>3</strong> 美元、输出 <strong>15</strong> 美元不变。</p>
<p>性能提升显著。在编程方面，根据 <code>Claude Code</code> 的早期测试，约 <strong>70%</strong> 的开发者更偏好 <code>Sonnet 4.6</code> 而非上代模型，<strong>59%</strong> 的用户选择它而非旗舰 <code>Opus 4.5</code>。用户反馈其在修改代码前能更有效阅读上下文，并减少“偷懒”行为。在计算机使用能力上，<code>OSWorld</code> 基准测试得分从 <strong>14.0%</strong> 大幅提升至 <strong>72.5%</strong>，能更有效地处理复杂电子表格和多步网页表单任务。据外部评估，<code>Sonnet 4.6</code> 在部分真实工作任务基准上略微优于 <code>Opus 4.6</code>。</p>
<p><strong>Anthropic</strong> 同步推出改进版 <code>Web Search</code> 和 <code>Web Fetch</code> 工具，通过 <code>代码执行</code> 对搜索结果进行动态过滤，官方数据显示平均准确率提升 <strong>11%</strong>，输入 Token 消耗减少 <strong>24%</strong>。<code>Sonnet 4.6</code> 现已上线 <code>API</code> 及各类AI应用，免费版 <strong>Claude</strong> 也可体验<code>Sonnet 4.6</code>。官方建议，对于大规模代码重构等超复杂任务，<code>Opus 4.6</code> 仍是最佳选择，但对多数任务，<code>Sonnet 4.6</code> 提供了极高性价比。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/37ae8237-3741-4ff4-950b-a7944f9f7c68/m001.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/37ae8237-3741-4ff4-950b-a7944f9f7c68/m002.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/37ae8237-3741-4ff4-950b-a7944f9f7c68/m003.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.anthropic.com/news/claude-sonnet-4-6">https://www.anthropic.com/news/claude-sonnet-4-6</a></li>
<li><a href="https://claude.com/blog/improved-web-search-with-dynamic-filtering">https://claude.com/blog/improved-web-search-with-dynamic-filtering</a></li>
</ul>
<hr />
<h2><a href="https://x.com/elonmusk/status/2023828048580387001">xAI 上线 Grok 4.20 测试版</a> <code>#2</code></h2>
<blockquote>
<p><strong>xAI</strong> 上线了 <code>Grok 4.20</code> 公开测试版，该版本引入了由四个 <code>Agent</code> 组成的 <code>原生协作系统</code>，用于处理复杂查询。据 <strong>Elon Musk</strong> 称，该版本基于 <strong>5000 亿</strong>参数的 <code>V8</code> 模型，凭借快速学习与每周迭代，<strong>下个月</strong>测试结束时，其智能水平和速度预计将比 <code>Grok 4</code> 提升约一个数量级。</p>
</blockquote>
<p><strong>xAI</strong>上线了<code>Grok 4.20</code>公开测试版，用户需在应用内手动选择。据创始人<strong>Elon Musk</strong>透露，该模型并非单纯迭代，而是基于<strong>500B</strong>参数的<code>V8</code>小型基础模型构建。官方声明指出，<code>Grok 4.2</code>基础设施支持快速学习与每周更新，以实现“<code>递归智能增长</code>”。官方预计，在下个月测试版结束时，其智能水平和速度将比<code>Grok 4</code>提升约一个数量级。</p>
<p>该版本引入的原生<code>多Agent协作系统</code>是其核心亮点。据了解，该系统包含<code>Grok/Captain</code>、<code>Harper</code>、<code>Benjamin</code>和<code>Lucas</code> <strong>四个</strong> Agent，在处理复杂查询时自动运行。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/7078bb72-ab29-4eeb-9a0a-1c0a2666c81d/m001.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/7078bb72-ab29-4eeb-9a0a-1c0a2666c81d/m002.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/7078bb72-ab29-4eeb-9a0a-1c0a2666c81d/m003.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/7078bb72-ab29-4eeb-9a0a-1c0a2666c81d/m004.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/elonmusk/status/2023828048580387001">https://x.com/elonmusk/status/2023828048580387001</a></li>
</ul>
<hr />
<h2><a href="https://x.com/NotebookLM/status/2023851190102986970">NotebookLM推出幻灯片Prompt修订与PPTX导出</a> <code>#3</code></h2>
<blockquote>
<p><strong>NotebookLM</strong> 发布重要更新，现在可以直接输入提示词来微调和修改幻灯片内容。同时，系统新增了 <code>PPTX</code> 导出支持，允许用户将生成的演示文稿直接下载为 <code>PPTX</code> 文件。这两项功能目前正在向 <strong>Ultra</strong> 和 <strong>Pro</strong> 会员推送。</p>
</blockquote>
<p><code>NotebookLM</code> 发布两项重要更新：<code>Prompt-Based Revisions</code> 与 <code>PPTX Support</code>，以回应用户强烈需求。</p>
<p>核心功能 <code>Prompt-Based Revisions</code> 允许用户通过 <code>Prompt</code> 描述直接对幻灯片进行调整、定制和微调。此外，<code>NotebookLM</code> 现已支持将生成的幻灯片导出为 <code>PPTX</code> 格式，官方透露 <strong>Google Slides</strong> 的支持即将推出。<code>NotebookLM</code> 正为 <code>Ultra</code> 和 <code>Pro</code> 会员推送这两项新功能：</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/a726e5fc-b654-42ea-9d19-ca3d11dc9ace/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://x.com/NotebookLM/status/2023851190102986970">https://x.com/NotebookLM/status/2023851190102986970</a></li>
</ul>
<hr />
<h2><a href="https://xqacmer.github.io/Ming-Flash-Omni-V2-TTS/">蚂蚁集团开源Ming-omni-tts音频生成模型</a> <code>#4</code></h2>
<blockquote>
<p><strong>蚂蚁集团</strong> <code>Inclusion AI</code> 开源了统一音频生成模型 <code>Ming-Omni-TTS</code>。该模型不仅能生成语音，还能合成音乐和环境音，包含 <strong>0.5B</strong> 和 <strong>16.8B-A3B</strong> 两个版本。</p>
</blockquote>
<p><strong>蚂蚁集团</strong> <strong>inclusionAI</strong> 开源统一音频生成模型 <code>Ming-omni-tts</code>，提供 <strong>0.5B</strong> 及 <code>16.8B-A3B</code> 两个版本。该模型是业界首个在单通道内联合生成语音、环境音和音乐的 <code>自回归模型</code>，通过定制 <strong>12.5Hz</strong> 连续 <code>Tokenizer</code> 实现了 <strong>3.1Hz</strong> 的高效推理帧率。官方评测显示，<code>Ming-omni-tts-16.8B-A3B</code> 在粤语生成、情感控制及零样本语音克隆等基准测试中达到 <code>SOTA</code> 水平，其文本规范化能力媲美 <code>Gemini-2.5 Pro</code>。模型权重及推理代码已上线 <strong>Hugging Face</strong>、<strong>ModelScope</strong> 及 <strong>GitHub</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/ea284cf1-f5d6-42cf-a715-7f1e71cee91c/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://xqacmer.github.io/Ming-Flash-Omni-V2-TTS/">https://xqacmer.github.io/Ming-Flash-Omni-V2-TTS/</a></li>
<li><a href="https://github.com/inclusionAI/Ming-omni-tts">https://github.com/inclusionAI/Ming-omni-tts</a></li>
<li><a href="https://modelscope.cn/studios/antsipan/ming-uniaudio-demo">https://modelscope.cn/studios/antsipan/ming-uniaudio-demo</a></li>
</ul>
<hr />
<h2><a href="https://cohere.com/blog/cohere-labs-tiny-aya">Cohere Labs发布Tiny Aya多语言模型</a> <code>#5</code></h2>
<blockquote>
<p><strong>Cohere Labs</strong> 发布了名为 <code>Tiny Aya</code> 的多语言小型模型家族。该系列拥有 <strong>33.5 亿</strong> 参数，覆盖全球 <strong>70 多种</strong> 语言。</p>
</blockquote>
<p><strong>Cohere Labs</strong> 发布多语言小型模型家族 <code>Tiny Aya</code>。该系列包含 <strong>3.35B</strong> 参数基座模型及 <strong>4</strong> 个针对全球及特定区域（南亚、西亚/非洲、欧亚）优化的指令微调模型，覆盖 <strong>70+</strong> 种语言，侧重低资源语言支持。模型上下文 <strong>8K</strong>，采用 <code>CC-BY-NC</code> 协议，支持在笔记本电脑及手机端离线运行。官方指出模型擅长翻译与摘要，但在思维链推理任务上表现较弱。目前模型已在 <strong>Hugging Face</strong>、<strong>Kaggle</strong> 等平台开源，提供 <code>GGUF</code> 格式。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/88832ab7-c4cc-48f2-9407-70a7fc40e493/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://cohere.com/blog/cohere-labs-tiny-aya">https://cohere.com/blog/cohere-labs-tiny-aya</a></li>
<li><a href="https://github.com/Cohere-Labs/tiny-aya-tech-report/blob/main/tiny_aya_tech_report.pdf">https://github.com/Cohere-Labs/tiny-aya-tech-report/blob/main/tiny_aya_tech_report.pdf</a></li>
<li><a href="https://huggingface.co/collections/CohereLabs/tiny-aya">https://huggingface.co/collections/CohereLabs/tiny-aya</a></li>
</ul>
<hr />
<h2><a href="https://github.com/shallowdream204/BitDance">字节跳动研究团队开源 BitDance 多模态模型</a> <code>#6</code></h2>
<blockquote>
<p><strong>字节跳动</strong>研究团队发布了名为 <code>BitDance</code> 的开源多模态模型，参数量达 <strong>140 亿</strong>，该模型专为视觉生成优化，通过 <code>并行预测 Token</code>，推理速度比标准模型提升超过 <strong>30 倍</strong>。</p>
</blockquote>
<p><strong>字节跳动</strong>研究团队近日发布开源离散自回归多模态模型 <code>BitDance</code>，参数量为 <strong>14B</strong>。模型引入<code>大词汇量二元分词器</code>及<code>下一块扩散范式</code>，支持每步并行预测最多 <strong>64</strong> 个 <code>Token</code>，官方数据显示其比标准 <code>AR 模型</code>推理速度快 <strong>30 倍</strong>以上。</p>
<p>官方发布了 <code>BitDance-14B-64x</code> 和 <code>16x</code> 两个版本，配套 <code>UniWeTok</code> 分词器。在性能方面，<code>BitDance</code> 在 <code>DPG-Bench</code>（<strong>88.28</strong> 分）和 <code>GenEval</code>（<strong>0.86</strong> 分）上表现优异。目前，该模型代码与权重已在 <strong>GitHub</strong> 和 <strong>Hugging Face</strong> 开源（<code>Apache 2.0</code>），并提供在线演示，相关论文已发布于 <strong>arXiv</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/a5632f31-cd75-4f9a-b20b-abc61940866e/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/shallowdream204/BitDance">https://github.com/shallowdream204/BitDance</a></li>
<li><a href="https://bitdance.csuhan.com/">https://bitdance.csuhan.com/</a></li>
<li><a href="https://huggingface.co/collections/shallowdream204/bitdance">https://huggingface.co/collections/shallowdream204/bitdance</a></li>
</ul>
<hr />
<h2><a href="https://cursor.com/changelog/2-5">Cursor 发布 2.5 版本更新，推出插件市场</a> <code>#7</code></h2>
<blockquote>
<p><strong>Cursor</strong> 发布了 <strong>2.5</strong> 版本更新，上线了 <strong>Cursor Marketplace</strong> 插件市场。首批整合了 <strong>Figma</strong>、<strong>Stripe</strong> 和 <strong>AWS</strong> 等工具。此外，<code>子智能体</code>现在支持<code>异步运行</code>与<code>树状协作</code>，<code>沙箱功能</code>新增了<code>细粒度访问控制</code>。</p>
</blockquote>
<p>近日，代码编辑器 <strong>Cursor</strong> 正式发布 <code>2.5</code> 版本，上线了 <code>Cursor Marketplace</code> 插件市场，并对核心 <code>Agent</code> 功能与 <code>沙盒</code> 安全机制进行了升级。</p>
<p>在扩展性方面，新版本引入统一<code>插件</code>机制，将 <code>Skills</code>、<code>Subagents</code>、<code>MCP servers</code> 等能力打包。<code>Cursor Marketplace</code> 已汇集 <strong>Linear</strong>、<strong>Figma</strong>、<strong>Stripe</strong>、<strong>AWS</strong> 等首批合作伙伴插件，覆盖设计、支付、部署及数据分析全流程。用户可通过网页或编辑器内 <code>/add-plugin</code> 命令直接安装。官方已开放插件提交入口，并发布了其内部 <code>CI</code> 和 <code>代码审查</code> 工作流模板 <code>Cursor Team Kit</code>，未来将推出支持统一治理的私有团队插件市场。</p>
<p>在 <code>Agent</code> 性能方面，<code>子智能体</code> 现已支持异步运行与树状层级协作，使<code>父智能体</code>可在后台执行任务，以更低的延迟处理大型重构或多文件任务。基于此，官方推出了具备自主规划与执行能力的 <code>长期运行智能体</code>，官方称在测试中已能生成更完整的 <code>PR</code> 并减少后续干预。</p>
<p>在安全与权限控制方面，<code>沙盒</code> 新增了对域名和本地文件系统的细粒度访问控制，提供 <code>仅用户配置</code>、<code>用户配置+默认值</code> 及 <code>允许全部</code> 三种模式。企业版管理员可通过 <code>管理控制台</code> 强制实施网络策略，确保组织级的出站访问安全。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/be845020-a5ba-43a5-a15f-fac997938c77/m001.png" alt="" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/be845020-a5ba-43a5-a15f-fac997938c77/m002.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://cursor.com/changelog/2-5">https://cursor.com/changelog/2-5</a></li>
<li><a href="https://cursor.com/blog/marketplace">https://cursor.com/blog/marketplace</a></li>
</ul>
<hr />
<h2><a href="https://developers.openai.com/codex/concepts/cyber-safety">OpenAI修复GPT-5.3-Codex请求重定向问题</a> <code>#8</code></h2>
<blockquote>
<p>针对部分用户使用 <code>GPT-5.3-Codex</code> 却被路由至 <code>GPT-5.2</code> 的问题，<strong>OpenAI</strong> 称已修复相关 <code>Bug</code> 并校准了 <code>分类器</code>，同时在 <code>CLI</code> <strong>v0.102.0</strong> 版本中加入了显眼的降级通知功能。</p>
</blockquote>
<p><strong>OpenAI</strong> 将 <code>GPT-5.3-Codex</code> 定义为其 <strong>Preparedness Framework</strong> 下的首个**“高网络安全能力”**模型。鉴于网络能力具备支持防御性研究与潜在恶意滥用的双重用途属性，<strong>OpenAI</strong> 实施了包括<code>安全训练</code>和<code>自动监控</code>在内的多重防护措施，会将检测到的<code>可疑网络活动流量</code> <code>重路由</code>至网络能力较弱的 <code>GPT-5.2</code> 模型。</p>
<p>针对近期用户遭遇请求被意外降级的情况，<strong>OpenAI</strong> 团队成员承认，系统曾在特定时段出现<code>过度标记问题</code>，影响了约 <strong>9%</strong> 的用户。该问题已修复，团队通过<code>校准分类器</code>将预期受影响用户比例降至 <strong>1%</strong> 以下，并修复了<code>信任访问权限</code>未生效的 <code>Bug</code>。为提升透明度，<code>CLI v0.102.0</code> 版本已加入请求被降级时的<code>显眼通知</code>，并将在未来几天内扩展至所有客户端。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/01abe632-e2e8-4802-9ff8-8b94bfbd5b27/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://developers.openai.com/codex/concepts/cyber-safety">https://developers.openai.com/codex/concepts/cyber-safety</a></li>
<li><a href="https://x.com/embirico/status/2023891414623592653">https://x.com/embirico/status/2023891414623592653</a></li>
</ul>
<hr />
<h2><a href="https://inference-docs.cerebras.ai/models/overview">Cerebras下调部分免费层级的推理额度</a> <code>#9</code></h2>
<blockquote>
<p><strong>Cerebras</strong> 官方宣布，由于部分模型需求量激增，已暂时下调相关模型免费层级的 <code>速率限制</code>。</p>
</blockquote>
<p><strong>Cerebras</strong>官方宣布，因<code>zai-glm-4.7</code>和<code>qwen-3-235b-a22b-instruct-2507</code>模型需求激增，已暂时下调免费层级<code>速率限制</code>，正致力恢复原有设置。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/c0ebb726-a3e0-4afc-8ae0-a410a7df87ea/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://inference-docs.cerebras.ai/models/overview">https://inference-docs.cerebras.ai/models/overview</a></li>
</ul>
<hr />
<h2><a href="https://github.com/Intelligent-Internet/CommonGround">Intelligent Internet 开源多Agent协作系统 Common Ground Core</a> <code>#10</code></h2>
<blockquote>
<p><strong>Intelligent Internet</strong> 宣布开源 <code>多 Agent</code> 协作操作系统 <code>Common Ground Core</code>，这是一个协议优先的 <code>OS</code> 内核，旨在解决 <code>多 Agent 系统</code> 常见的上下文丢失等问题。</p>
</blockquote>
<p><strong>Intelligent Internet</strong> 团队近日开源 <code>多 Agent 协作操作系统</code> <strong>Common Ground Core (CGC)</strong>。该系统定位为 <code>协议优先的 OS 内核</code>，旨在解决 <code>多 Agent</code> 扩展时的 <code>上下文丢失</code>、<code>死锁</code> 及 <code>协调崩溃</code> 等问题。<strong>CGC</strong> 采用 <code>边缘自由、内核约束</code> 设计，利用 <strong>Postgres</strong> 维护 <code>不可变共享认知账本</code> 作为 <code>真理源</code>，通过 <strong>NATS</strong> 消除 <code>分布式消息重排序风险</code>。系统将人类视为与 AI 平等的 <code>异步节点</code>，支持介入协作。目前项目已在 <strong>GitHub</strong> 发布 <code>预览版</code>，提供 <strong>Docker</strong> 部署并集成 <strong>CardBox</strong> 状态模型。官方特别提示，当前版本 <code>API</code> 无认证且具备 <code>任意命令执行能力</code>，严禁直接暴露于 <code>公网</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/b928c84e-5235-405d-819a-51c14e1ad9d8/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://github.com/Intelligent-Internet/CommonGround">https://github.com/Intelligent-Internet/CommonGround</a></li>
<li><a href="https://ii.inc/web/blog/post/common-ground-core-cgc">https://ii.inc/web/blog/post/common-ground-core-cgc</a></li>
</ul>
<hr />
<h2><a href="https://www.usenerve.com/blog/joining-openai">Nerve加入OpenAI构建ChatGPT搜索</a> <code>#11</code></h2>
<blockquote>
<p>初创公司 <strong>Nerve</strong> 宣布加入 <strong>OpenAI</strong>，团队将致力于在更大规模上为 <strong>ChatGPT</strong> 构建搜索功能。</p>
</blockquote>
<p>企业级 <code>AI Agent</code> 初创公司 <strong>Nerve</strong> 官方宣布加入 <strong>OpenAI</strong>，旨在为 <code>ChatGPT</code> 构建更大规模的搜索功能。<strong>Nerve</strong> 过去 <strong>两年</strong> 专注于以搜索为核心的企业级 <code>Agent</code>，因认可 <strong>OpenAI</strong> 在 <code>信息检索</code> 领域的深度与雄心而决定加入。针对现有客户，<strong>Nerve</strong> 宣布产品将在 <strong>30 天后</strong> 正式关停，即日起暂停所有计费；未来 <strong>30 天内</strong> 服务将继续运行并提供支持，过渡期结束后将安全删除所有客户数据。</p>
<p><img src="https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/e48a712e-9804-40a3-83ef-a724b8c835d1/970fab9f-d63e-4427-96e6-c64530e0cae8/m001.png" alt="" /></p>
<p>相关链接：</p>
<ul>
<li><a href="https://www.usenerve.com/blog/joining-openai">https://www.usenerve.com/blog/joining-openai</a></li>
</ul>
<hr />
<h2><a href="https://mp.weixin.qq.com/s/MRx63AOgKZcn9ug8aSiH6w">传 Moonshot AI 完成7亿美元融资</a> <code>#12</code></h2>
<blockquote>
<p>据媒体报道，<strong>月之暗面</strong>完成<strong>7亿美元</strong>融资，<strong>阿里巴巴</strong>和<strong>腾讯</strong>参与投资，公司投后估值超过<strong>100亿美元</strong>。</p>
</blockquote>
<p>据媒体报道，<strong>Moonshot AI（月之暗面）<strong>完成</strong>7亿美元</strong>融资，投后估值超<strong>100亿美元</strong>。本轮融资由<strong>Alibaba</strong>与<strong>Tencent</strong>参与。</p>
<p>相关链接：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/MRx63AOgKZcn9ug8aSiH6w">https://mp.weixin.qq.com/s/MRx63AOgKZcn9ug8aSiH6w</a></li>
</ul>
<hr />
<p><strong>提示</strong>：内容由AI辅助创作，可能存在<strong>幻觉</strong>和<strong>错误</strong>。</p>
<p>作者<code>橘鸦Juya</code>，视频版在同名<strong>哔哩哔哩</strong>。欢迎<strong>点赞、关注、分享</strong>。</p>
]]></content><link href="https://github.com/imjuya/juya-ai-daily/issues/1"/><published>2026-02-17T13:18:21+00:00</published></entry></feed>