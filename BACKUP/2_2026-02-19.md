# [2026-02-19](https://github.com/imjuya/juya-ai-daily/issues/2)

![](http://testtttt.oss-cn-guangzhou.aliyuncs.com/imagehub/20260219/20260219090351005487a008_cover_73fa.png)

# AI 早报 2026-02-19

**视频版**：[YouTube](https://www.youtube.com/watch?v=qaQ1uDPjCqk) ｜ [哔哩哔哩](https://www.bilibili.com/video/BV1WfZ8BqEu6)

## 概览
### 模型发布
- Google DeepMind发布Lyria 3音乐生成模型 `#1`
- xAI 发布16-Agent协作模式 Grok 4.20 Heavy `#2`
- Prime Intellect开源106B参数MoE模型 `#3`
- 印度AI企业Sarvam发布Sarvam-30B与105B `#4`
### 开发生态
- OpenAI 开源 Codex App Server 支持ChatGPT登录 `#5`
- Figma 推出 Claude Code to Figma 功能 `#6`
- OpenAI发布智能合约安全基准EVMbench `#7`
- Gemini CLI 推出 v0.29.0 版本每周更新 `#8`
### 行业动态
- 谷歌、OpenAI 和微软宣布在印计划 `#9`
- Perplexity撤下搜索平台广告 `#10`
- World Labs完成融资并与Autodesk合作 `#11`
### 技术与洞察
- 智谱AI发布GLM-5技术报告 `#12`

---

## [Google DeepMind发布Lyria 3音乐生成模型](https://deepmind.google/models/lyria/) `#1`
> **Google DeepMind** 发布音乐生成模型 `Lyria 3`，并已在 `Gemini` 桌面端开启测试。用户只需输入文字描述或上传图片、视频，即可生成 **30 秒** 带歌词的 `高保真` 音乐，且支持对风格和人声的精细控制。该功能面向 **18 岁** 以上用户开放，生成的所有音轨均嵌入 `SynthID` 水印，以确保可追溯性。

**Google DeepMind** 发布最先进音乐生成模型 **Lyria 3**，并已在 **Gemini App** 中推出 Beta 版。用户可以通过 `文本转音轨` 功能，描述特定的流派、情绪、记忆甚至内部笑话来生成音乐；也可以利用 `图像/视频转音轨` 功能，上传照片或视频，让 AI 根据视觉内容的氛围自动谱曲并填写歌词。**Gemini App** 生成的音轨时长固定为 **30** 秒，并附带由 `Nano Banana` 生成的自定义封面图。

官方指出，**Lyria 3** 的 **三大** 改进点包括：自动生成歌词无需用户提供、提供对风格及人声和节奏的更强控制、以及生成更真实且音乐结构更复杂的曲目。该服务目前向所有 **18** 岁及以上的 **Gemini** 用户开放，支持英语、德语、西班牙语、法语、印地语、日语、韩语和葡萄牙语。桌面端现已可用，移动端预计将在未来几天内上线，**Google AI Plus**、**Pro** 和 **Ultra** 订阅用户将享有更高的使用额度。在 **Gemini** 应用中生成的所有音轨均嵌入了 `SynthID`，**Gemini** 亦上线了 `音频验证工具`。

![](https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/f050b0b0-bd7f-4176-b7e3-b545c975855d/m001.png)

相关链接：
- [https://deepmind.google/models/lyria/](https://deepmind.google/models/lyria/)
- [https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/)

---

## [xAI 发布16-Agent协作模式 Grok 4.20 Heavy](https://x.com/elonmusk/status/2024194618930401590) `#2`
> **Elon Musk** 宣布**xAI**上线 `Grok 4.20 Heavy` 并向 Heavy 订阅用户开放。该模型核心架构为由 **16** 个专门化 `Agent` 组成的协作团队。

**Elon Musk**宣布推出`Grok 4.20 Heavy`，称其为重大升级，现已向**Heavy**订阅者开放。该版本核心变化在于底层架构调整，即在`grok-4.20架构`下运行由**16**个专门化`Agent`组成的团队进行`实时协作`。

![](https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/e0145bc4-033f-4528-bfb5-5821485d31b6/m001.png)

相关链接：
- [https://x.com/elonmusk/status/2024194618930401590](https://x.com/elonmusk/status/2024194618930401590)
- [https://x.com/tetsuoai/status/2024121909286494435](https://x.com/tetsuoai/status/2024121909286494435)

---

## [Prime Intellect开源106B参数MoE模型](https://huggingface.co/PrimeIntellect/INTELLECT-3.1) `#3`
> **Prime Intellect** 发布了基于 `GLM-4.5-Air-Base` 通过 `强化学习` 训练的 `INTELLECT-3.1` 模型，显著提升了在数学、编程及 `Agent` 任务上的表现。

**Prime Intellect** 发布开源推理模型 `INTELLECT-3.1`。该模型采用 `Mixture-of-Experts (MoE)` 架构，拥有 **106B** 总参数及 **A12B** 活跃参数，基于 `zai-org/GLM-4.5-Air-Base` 并结合 `prime-rl` 框架进行了强化学习训练，重点提升了数学、编程、软件工程和 `Agent` 任务的能力。

官方已将模型、训练框架及环境以 `MIT` 和 `Apache 2.0` 协议完全开源，并提供了技术报告。

相关链接：
- [https://huggingface.co/PrimeIntellect/INTELLECT-3.1](https://huggingface.co/PrimeIntellect/INTELLECT-3.1)

---

## [印度AI企业Sarvam发布Sarvam-30B与105B](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai) `#4`
> 印度AI初创公司**Sarvam**发布了从零训练的`Sarvam-30B`和`Sarvam-105B`混合专家架构模型。根据官方数据，这两款模型针对印度本土语言进行了优化，在多项基准测试中表现出色。

印度AI初创公司**Sarvam**近日发布了**两款**从零训练的`大型语言模型``Sarvam-30B`和`Sarvam-105B`，并同步推出语音及视觉模型。核心模型采用`混合专家架构`，获**印度政府**、**Yotta**及**Nvidia**支持。其中，**30B**模型预训练数据达**16T** `Token`，支持**32k** `上下文`；**105B**模型支持**128k** `上下文`，专攻复杂推理。官方数据显示，其性能优于或持平`Gemma`、`Qwen`等竞品。**Sarvam**计划开源**这两款**模型，并推出**“Sarvam for Work”**企业工具及**“Samvaad”**对话`Agent`平台。

![](https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/d06d1a70-4751-4a0e-a57a-33b53050c804/m001.png)

![](https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/d06d1a70-4751-4a0e-a57a-33b53050c804/m002.png)

相关链接：
- [https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai)

---

## [OpenAI 开源 Codex App Server 支持ChatGPT登录](https://developers.openai.com/codex/app-server/) `#5`
> **OpenAI** 开源了驱动 Codex 应用的底层框架 `Codex App Server`，允许开发者将 `Codex Agent` 深度集成到自有产品中。该工具支持通过 **ChatGPT** 账号 `OAuth` 直接接入第三方应用。

**OpenAI** 已开源其核心接口 `Codex App Server`，旨在让开发者在自有产品中深度集成 `Codex Agent`。该服务器是 Codex 富客户端（如 `VS Code` 扩展）的底层驱动，支持通过 **ChatGPT** 账号 `OAuth` 直接接入第三方应用，并提供身份验证、会话历史、审批流和流式 Agent 事件等完整功能。在协议层面，其采用类似 `MCP` 的 `JSON-RPC 2.0` 进行双向通信，支持 `stdio` 和实验性的 `websocket` 传输方式。客户端必须在连接后立即发送 `initialize` 请求并携带标识信息，企业级集成需在 **OpenAI** 平台注册。

![](https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/f1458b74-fc09-407d-9990-8504ee226fb2/m001.png)

相关链接：
- [https://developers.openai.com/codex/app-server/](https://developers.openai.com/codex/app-server/)
- [https://github.com/openai/codex/tree/main/codex-rs/app-server](https://github.com/openai/codex/tree/main/codex-rs/app-server)

---

## [Figma 推出 Claude Code to Figma 功能](https://www.figma.com/blog/introducing-claude-code-to-figma/) `#6`
> **Figma** 近期推出 `Claude Code to Figma` 功能，利用 `Figma MCP Server`，能够将 `Claude Code` 生成的 `UI` 直接转化为 **Figma** 画布上的可编辑 `Frame`。

**Figma** 近期推出“`Claude Code` to **Figma**”功能，通过更新**Figma**`MCP server`，打通代码构建与设计协作。开发者可将`Claude Code`生成的真实`UI`转化为**Figma**画布上可编辑的`Frame`，支持捕捉完整流程并保留上下文，从而实现从“代码收敛”到“画布发散”的高效转换。该功能允许团队直接对代码生成的界面进行协作，避免了截图反馈的摩擦，并支持从设计回到代码的“往返”工作流。

![](https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/1aadc184-cda8-4630-858b-7a5f6b3a2db2/m001.gif)

相关链接：
- [https://www.figma.com/blog/introducing-claude-code-to-figma/](https://www.figma.com/blog/introducing-claude-code-to-figma/)

---

## [OpenAI发布智能合约安全基准EVMbench](https://openai.com/index/introducing-evmbench/) `#7`
> **OpenAI** 与 **Paradigm** 联合推出了`智能合约安全基准` `EVMbench`，旨在评估 `AI Agent` 在检测、修补及利用高危漏洞方面的`实战能力`。

**OpenAI** 联合 **Paradigm** 发布 `EVMbench` 基准，旨在评估 `AI Agent` 在 `智能合约` 安全领域（`检测`、`修补`、`利用`）的能力。该基准包含 **120** 个源自 **40** 次审计的漏洞场景，并配备基于 `Rust` 的测试工具和 `隔离沙盒` 环境。

官方评估显示，`GPT-5.3-Codex` 在 `Exploit` 模式得分 **72.2%**，显著优于 `GPT-5` 的 **31.9%**，但在 `检测` 和 `修补` 方面仍有提升空间。**OpenAI** 承认该基准存在环境与评分机制局限，不完全代表现实难度。

相关链接：
- [https://openai.com/index/introducing-evmbench/](https://openai.com/index/introducing-evmbench/)

---

## [Gemini CLI 推出 v0.29.0 版本每周更新](https://github.com/google-gemini/gemini-cli/discussions/19473) `#8`
> `Gemini CLI` 推出 `v0.29.0` 版本更新，新增 `Ask User Tool` 支持模型交互式提问以澄清指令，同时引入 `Conductor` 和 `Firebase Agent Skills` 扩展，并上线了实验性 `Plan Mode`。

**Gemini CLI** 近日推出 **v0.29.0** 版本更新，新增 `Ask User Tool`，支持模型交互式暂停并询问用户以获取澄清。官方扩展了生态系统，引入 **Conductor** 扩展用于自动化逻辑审查与合规报告，以及 **Firebase Agent Skills** 扩展以优化开发体验。性能方面，更新优化了对海量工具输出的处理，防止 `上下文窗口` 过载，从而支持更长时间的高质量推理；同时改进了 `Vim` 编辑体验（支持 `W`、`B`、`E` 动作）及快捷键可发现性（按 `?` 唤起）。此外，官方首推实验性 `Plan Mode`，该只读模式旨在帮助用户在不修改文件的前提下映射代码库并验证假设。

相关链接：
- [https://github.com/google-gemini/gemini-cli/discussions/19473](https://github.com/google-gemini/gemini-cli/discussions/19473)

---

## [谷歌、OpenAI 和微软宣布在印计划](https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/) `#9`
> 在新德里 `AI Impact Summit` 上，**谷歌**、**OpenAI** 和 **微软** 密集公布了它们在印度的最新计划。**谷歌**启动了连接美印的`战略光纤倡议`；**OpenAI** 联合当地顶尖高校，将 `ChatGPT Edu` 引入高等教育体系；**微软** 则承诺在印度培训 **2000 万人**。

本周在新德里**AI Impact Summit**期间，**Google**、**OpenAI**和**Microsoft**密集公布在印扩展计划。**Google**启动“**America-India Connect**”光缆基建倡议，连接美印及南半球；**Google.org**投入共**6000万美元**用于科学及政府创新挑战赛，并深化在教育、农业及能源领域的`AI模型`部署。**OpenAI**通过与印度顶尖高校合作，将`ChatGPT Edu`整合进高等教育体系，覆盖逾**10万**师生。**Microsoft**宣布到本十年末向“**全球南方**”投资**500亿美元**，其中计划在**2030年**前培训**2000万**印度人。

相关链接：
- [https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/](https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/)
- [https://techcrunch.com/2026/02/18/openai-pushes-into-higher-education-as-india-seeks-to-scale-ai-skills](https://techcrunch.com/2026/02/18/openai-pushes-into-higher-education-as-india-seeks-to-scale-ai-skills)

---

## [Perplexity撤下搜索平台广告](https://www.ft.com/content/6eec07a5-34a8-4f78-a9ed-93ab4263d43c) `#10`
> 据报道，**Perplexity**将撤下平台所有广告，以确保用户信任和搜索准确性。公司战略重心现已转向订阅服务和企业销售，并计划积极扩充销售团队。

据报道，AI 搜索初创公司 **Perplexity** 将从平台撤下广告，以维护用户信任，坚持“准确性企业”定位。该公司高管表示不会在聊天机器人答案中投放广告，未来将专注于订阅服务和企业销售。公司目前正锁定大型企业及财务、医疗等高端用户，企业销售计划积极扩张。

相关链接：
- [https://www.ft.com/content/6eec07a5-34a8-4f78-a9ed-93ab4263d43c](https://www.ft.com/content/6eec07a5-34a8-4f78-a9ed-93ab4263d43c)

---

## [World Labs完成融资并与Autodesk合作](https://www.worldlabs.ai/blog/funding-2026) `#11`
> **李飞飞**创立的 **World Labs** 宣布完成 **10亿美元** 新一轮融资，**AMD** 和 **英伟达** 等巨头参投。与此同时，**Autodesk**向其投入 **2亿美元** 并达成战略合作，计划将 **World Labs** 的 `空间智能模型` 与自家的 `3D 工具` 相结合。

**李飞飞**创立的AI初创公司**World Labs**近日宣布完成**10亿美元**新一轮融资，本轮融资由**AMD**、**Autodesk**、**NVIDIA**等机构共同参与。**World Labs**致力于通过构建`World Models`来推进空间智能发展。

软件设计巨头**Autodesk**在本轮融资中投资了**2亿美元**，并与**World Labs**达成战略合作。双方初期将聚焦于媒体和娱乐领域，探索将**World Labs**的模型与**Autodesk**的`3D工具`及正在开发的新一代生成式AI模型`Neural CAD`相结合，旨在为设计、建筑及娱乐行业提供更高级的物理AI解决方案。据**Autodesk**首席科学家**Daron Green**称，合作尚处早期阶段，且双方协议明确不包含数据共享。

相关链接：
- [https://www.worldlabs.ai/blog/funding-2026](https://www.worldlabs.ai/blog/funding-2026)

---

## [智谱AI发布GLM-5技术报告](https://arxiv.org/abs/2602.15763) `#12`
> **智谱AI**在arXiv发布了`GLM-5`技术报告。该模型采用`DSA架构`，并已适配**7种**国产芯片。官方宣称，通过`异步Agent RL基础设施`及`Slime RL工具包`等创新， `GLM-5` 在开源模型中实现了`SOTA性能`。

**智谱AI**近日在**arXiv**上发布`GLM-5`技术报告，详述其架构与训练细节。该模型采用`DSA`架构，拥有**750B**总参数与**40B**激活参数，训练数据量达**30T**，并已完成对**7**种国产芯片的适配。

报告揭示了多项核心创新。`DSA`架构旨在降低训练推理成本并保持长上下文保真度。模型引入`Slime RL`工具包与`异步Agent RL`基础设施，通过解耦生成与训练过程提升后训练效率。技术实现细节上，`GLM-5`的`RL`算法使用了带有双向`Token级掩码`的`GRPO`。为提升效率，系统采用`FP8`减少Token间延迟，实施平均接受长度为**2.76**的`多Token预测`，并利用`数据并行感知路由`最大化`KV-cache`复用。此外，`Prefill-Decode分离技术`可避免处理干扰。其`异步Agent RL`系统基于样本阈值更新模型，会主动丢弃过旧或崩溃环境的样本，并通过`Token-in Token-out`机制对齐推理与训练，`混合式奖励系统`则衡量基础正确性、情商与任务质量。

![](https://cdn.jsdelivr.net/gh/imjuya/picx-images-hosting@master/imagehub/aidaily/73facf84-16ad-4d1b-8f5a-f3decce3eae0/f93b154d-a72b-4e76-8770-06eec166737e/m001.png)

相关链接：
- [https://arxiv.org/abs/2602.15763](https://arxiv.org/abs/2602.15763)
- [https://x.com/Zai_org/status/2023951884826849777](https://x.com/Zai_org/status/2023951884826849777)

---

**提示**：内容由AI辅助创作，可能存在**幻觉**和**错误**。

作者`橘鸦Juya`，视频版在同名**哔哩哔哩**。欢迎**点赞、关注、分享**。